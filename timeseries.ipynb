{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from collections import OrderedDict, defaultdict, Counter\n",
    "from dateutil import parser\n",
    "from datetime import datetime\n",
    "import pickle as pkl\n",
    "from itertools import chain\n",
    "from math import ceil\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import pearsonr, spearmanr, linregress\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "from matplotlib.patches import Rectangle\n",
    "import seaborn as sns\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "import gzip\n",
    "from functools import reduce\n",
    "\n",
    "from tqdm import tqdm\n",
    "import glob\n",
    "import os\n",
    "import subprocess\n",
    "\n",
    "import socialsim as ss\n",
    "register_matplotlib_converters()\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap = plt.get_cmap('tab10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# append = 'to_5_31'\n",
    "# append = 'to_6_29'\n",
    "# append = 'to_6_08'\n",
    "# append = 'to_7_06'\n",
    "# append = 'to_7_13'\n",
    "# append = 'to_7_20'\n",
    "# append = 'to_7_27'\n",
    "append = 'to_8_03'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# idx = pd.date_range(pd.to_datetime('2020-03-30'), pd.to_datetime('2020-05-31'))\n",
    "# idx = pd.date_range(pd.to_datetime('2020-03-30'), pd.to_datetime('2020-06-29'))\n",
    "# idx = pd.date_range(pd.to_datetime('2020-03-30'), pd.to_datetime('2020-06-08'))\n",
    "# idx = pd.date_range(pd.to_datetime('2020-03-30'), pd.to_datetime('2020-07-06'))\n",
    "# idx = pd.date_range(pd.to_datetime('2020-03-30'), pd.to_datetime('2020-07-13'))\n",
    "# idx = pd.date_range(pd.to_datetime('2020-03-30'), pd.to_datetime('2020-07-20'))\n",
    "# idx = pd.date_range(pd.to_datetime('2020-03-30'), pd.to_datetime('2020-07-27'))\n",
    "idx = pd.date_range(pd.to_datetime('2020-03-30'), pd.to_datetime('2020-08-03'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/data/leidos_extracted/2021CP5/cp5_eval_nodes.txt', 'r') as f:\n",
    "    evalNodes = f.read().split('\\n')[:-2]\n",
    "with open('/data/leidos_extracted/2021CP5/cp5_eval_nodes.txt', 'r') as f:\n",
    "    nodes = f.read().split('\\n')[:-2]\n",
    "with open('/data/leidos_extracted/2021CP5/cp5_other_nodes.txt', 'r') as f:\n",
    "    nodes += f.read().split('\\n')[:-1]\n",
    "nodes.append('empty')\n",
    "nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# GDLET (full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "records = []\n",
    "with open('/data/leidos/2021CP5/CPEC/Exogenous/GDELT/cp5-cpec.exogenous.gdelt.events.v1.json', 'r') as f:\n",
    "    for l in f:\n",
    "        records.append(json.loads(l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "alleventcodes = set()\n",
    "for r in records:\n",
    "    alleventcodes.add(r['EventCode'])\n",
    "alleventcodes = sorted(alleventcodes)\n",
    "df = pd.DataFrame(records)\n",
    "df.day = pd.to_datetime(df.day)\n",
    "df = df.sort_values('day')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "eventCountTimeseries = {}\n",
    "for code in alleventcodes:\n",
    "    tmp = df.query('EventCode == \"{}\"'.format(code))\n",
    "    counts = tmp.day.value_counts().resample('D').sum()\n",
    "    idxx = pd.date_range(pd.to_datetime('2020-03-30'), pd.to_datetime('2020-08-31'))\n",
    "    counts = counts[pd.to_datetime('2020-03-30'):pd.to_datetime('2020-09-01')].reindex(idxx, fill_value=0)\n",
    "    eventCountTimeseries[code] = counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "eventCountTimeseries_json = {k: v.to_json() for k, v in eventCountTimeseries.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "with open('/data/leidos_extracted/2021CP5/gdelt_time_series.json', 'w') as f:\n",
    "    f.write(json.dumps(eventCountTimeseries_json))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# ACLED (full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "acled = pd.read_csv('/data/leidos/2021CP5/CPEC/Exogenous/ACLED/cp5-cpec.exogenous.training.acled.v1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "acled.event_date = pd.to_datetime(acled.event_date)\n",
    "acled = acled.sort_values('event_date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "acledCountTimeseries = {}\n",
    "for code in acled.event_type.unique():\n",
    "    tmp = acled.query('event_type == \"{}\"'.format(code))\n",
    "    counts = tmp.event_date.value_counts().resample('D').sum()\n",
    "    idxx = pd.date_range(pd.to_datetime('2020-03-30'), pd.to_datetime('2020-08-31'))\n",
    "    counts = counts[pd.to_datetime('2020-03-30'):pd.to_datetime('2020-09-01')].reindex(idxx, fill_value=0)\n",
    "    acledCountTimeseries['_'.join(code.split())] = counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "acledCountTimeseries_json = {k: v.to_json() for k, v in acledCountTimeseries.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "with open('/data/leidos_extracted/2021CP5/acled_time_series.json', 'w') as f:\n",
    "    f.write(json.dumps(acledCountTimeseries_json))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Twitter (partial)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### infoID -> date -> (evt count, user set, unique user set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tdict_count = defaultdict(lambda: defaultdict(int))\n",
    "tdict_userset = defaultdict(lambda: defaultdict(set))\n",
    "tdict_activateduserset = defaultdict(lambda: defaultdict(set))\n",
    "t_userset = defaultdict(set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath = '/data/leidos_extracted/2021CP5/cp5_twitter_2020-03-30_2020-06-29.json'\n",
    "with open(datapath, 'rb') as f:\n",
    "    for line in tqdm(f, total=int(subprocess.check_output([\"wc\", \"-l\", datapath]).decode(\"utf8\").split()[0])):\n",
    "        tmp = json.loads(line)\n",
    "        date = pd.to_datetime(tmp['nodeTime']).date()\n",
    "        user = tmp['nodeUserID']\n",
    "        infoId = tmp['informationID']\n",
    "        \n",
    "        tdict_count[infoId][date] += 1\n",
    "        tdict_userset[infoId][date].add(user)\n",
    "        if user not in t_userset[infoId]:\n",
    "            tdict_activateduserset[infoId][date].add(user)\n",
    "        t_userset[infoId].add(user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#INSERT TEMPLATE\n",
    "# datapath = ''\n",
    "# with open(datapath, 'rb') as f:\n",
    "#     for line in tqdm(f, total=int(subprocess.check_output([\"wc\", \"-l\", datapath]).decode(\"utf8\").split()[0])):\n",
    "#         tmp = json.loads(line)\n",
    "#         date = pd.to_datetime(tmp['nodeTime']).date()\n",
    "#         user = tmp['nodeUserID']\n",
    "#         infoId = tmp['informationID']\n",
    "        \n",
    "#         tdict_count[infoId][date] += 1\n",
    "#         tdict_userset[infoId][date].add(user)\n",
    "#         if user not in t_userset[infoId]:\n",
    "#             tdict_activateduserset[infoId][date].add(user)\n",
    "#         t_userset[infoId].add(user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tdict_usercount = {k: {kk: len(vv) for kk, vv in v.items()} for k, v in tdict_userset.items()}\n",
    "tdict_activateduser = {k: {kk: len(vv) for kk, vv in v.items()} for k, v in tdict_activateduserset.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmerge = defaultdict(dict)\n",
    "for k, v in tdict_count.items():\n",
    "    for kk, vv in v.items():\n",
    "        if kk not in tdict_activateduser[k]:\n",
    "            tdict_activateduser[k][kk] = 0\n",
    "        tmerge[k][kk] = (vv, tdict_usercount[k][kk], tdict_activateduser[k][kk])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmerge_df = {k: pd.DataFrame.from_dict(v, orient='index', columns=['EventCount', 'UserCount', 'NewUserCount']).reindex(idx, fill_value=0) for k, v in tmerge.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(tmerge.keys()) == set(nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmerge_df_json = {k: v.to_json() for k, v in tmerge_df.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/data/leidos_extracted/2021CP5/twitter_time_series_{}.json'.format(append), 'w') as f:\n",
    "    f.write(json.dumps(tmerge_df_json))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tprob = defaultdict(lambda: defaultdict(lambda: [0, 0, 0, 0]))\n",
    "maxes = {}\n",
    "for node in nodes:\n",
    "    tmp = max(tmerge_df[node].EventCount)\n",
    "    maxes[node] = tmp\n",
    "    for date in tmerge_df[node].index:\n",
    "        cur = tmerge_df[node].loc[date].EventCount\n",
    "        if cur < tmp / 4:\n",
    "            for u in tdict_userset[node][date.date()]:\n",
    "                tprob[node][u][0] += 1\n",
    "        elif cur < tmp * 2 / 4:\n",
    "            for u in tdict_userset[node][date.date()]:\n",
    "                tprob[node][u][1] += 1\n",
    "        elif cur < tmp * 3 / 4:\n",
    "            for u in tdict_userset[node][date.date()]:\n",
    "                tprob[node][u][2] += 1\n",
    "        else:\n",
    "            for u in tdict_userset[node][date.date()]:\n",
    "                tprob[node][u][3] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/data/leidos_extracted/2021CP5/twitter_prob_{}.json'.format(append), 'w') as f:\n",
    "    json.dump({'span': len(idx), 'max': maxes, 'prob': tprob}, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# YouTube (partial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ydict_count = defaultdict(lambda: defaultdict(int))\n",
    "ydict_userset = defaultdict(lambda: defaultdict(set))\n",
    "ydict_activateduserset = defaultdict(lambda: defaultdict(set))\n",
    "y_userset = defaultdict(set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath = '/data/leidos_extracted/2021CP5/cp5_youtube_to_8_03.json'\n",
    "with open(datapath, 'rb') as f:\n",
    "    for line in tqdm(f, total=int(subprocess.check_output([\"wc\", \"-l\", datapath]).decode(\"utf8\").split()[0])):\n",
    "        tmp = json.loads(line)\n",
    "        date = pd.to_datetime(tmp['nodeTime']).date()\n",
    "        user = tmp['nodeUserID']\n",
    "        infoId = tmp['informationID']\n",
    "        \n",
    "        ydict_count[infoId][date] += 1\n",
    "        ydict_userset[infoId][date].add(user)\n",
    "        if user not in y_userset[infoId]:\n",
    "            ydict_activateduserset[infoId][date].add(user)\n",
    "        y_userset[infoId].add(user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#INSERT TEMPLATE\n",
    "# datapath = ''\n",
    "# with open(datapath, 'rb') as f:\n",
    "#     for line in tqdm(f, total=int(subprocess.check_output([\"wc\", \"-l\", datapath]).decode(\"utf8\").split()[0])):\n",
    "#         tmp = json.loads(line)\n",
    "#         date = pd.to_datetime(tmp['nodeTime']).date()\n",
    "#         user = tmp['nodeUserID']\n",
    "#         infoId = tmp['informationID']\n",
    "        \n",
    "#         ydict_count[infoId][date] += 1\n",
    "#         ydict_userset[infoId][date].add(user)\n",
    "#         if user not in t_userset[infoId]:\n",
    "#             ydict_activateduserset[infoId][date].add(user)\n",
    "#         y_userset[infoId].add(user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ydict_usercount = {k: {kk: len(vv) for kk, vv in v.items()} for k, v in ydict_userset.items()}\n",
    "ydict_activateduser = {k: {kk: len(vv) for kk, vv in v.items()} for k, v in ydict_activateduserset.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ymerge = defaultdict(dict)\n",
    "for k, v in ydict_count.items():\n",
    "    for kk, vv in v.items():\n",
    "        if kk not in ydict_activateduser[k]:\n",
    "            ydict_activateduser[k][kk] = 0\n",
    "        ymerge[k][kk] = (vv, ydict_usercount[k][kk], ydict_activateduser[k][kk])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ymerge_df = {k: pd.DataFrame.from_dict(v, orient='index', columns=['EventCount', 'UserCount', 'NewUserCount']).reindex(idx, fill_value=0) for k, v in ymerge.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in set(nodes) - set(ymerge.keys()):\n",
    "    print(k)\n",
    "    ymerge_df[k] = pd.DataFrame(columns=['EventCount', 'UserCount', 'NewUserCount']).reindex(idx, fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ymerge_df_json = {k: v.to_json() for k, v in ymerge_df.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/data/leidos_extracted/2021CP5/youtube_time_series_{}.json'.format(append), 'w') as f:\n",
    "    f.write(json.dumps(ymerge_df_json))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yprob = defaultdict(lambda: defaultdict(lambda: [0, 0, 0, 0]))\n",
    "maxes = {}\n",
    "for node in nodes:\n",
    "    if node not in ymerge_df:\n",
    "        maxes[node] = 0\n",
    "        yprob[node] = {}\n",
    "        continue\n",
    "    tmp = max(ymerge_df[node].EventCount)\n",
    "    maxes[node] = tmp\n",
    "    for date in ymerge_df[node].index:\n",
    "        cur = ymerge_df[node].loc[date].EventCount\n",
    "        if cur < tmp / 4:\n",
    "            for u in ydict_userset[node][date.date()]:\n",
    "                yprob[node][u][0] += 1\n",
    "        elif cur < tmp * 2 / 4:\n",
    "            for u in ydict_userset[node][date.date()]:\n",
    "                yprob[node][u][1] += 1\n",
    "        elif cur < tmp * 3 / 4:\n",
    "            for u in ydict_userset[node][date.date()]:\n",
    "                yprob[node][u][2] += 1\n",
    "        else:\n",
    "            for u in ydict_userset[node][date.date()]:\n",
    "                yprob[node][u][3] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/data/leidos_extracted/2021CP5/youtube_prob_{}.json'.format(append), 'w') as f:\n",
    "    json.dump({'span': len(idx), 'max': maxes, 'prob': yprob}, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('youtube_time_series.json', 'r') as f:\n",
    "#     d = json.loads(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dd = {k: pd.read_json(v, orient='columns') for k, v in d.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(int(ceil(len(nodes) / 3)), 3, True, False, True, figsize=(20, 17), dpi=200)\n",
    "for i in range(int(ceil(len(nodes) / 3))):\n",
    "    for j in range(3):\n",
    "        if i * 3 + j >= len(nodes):\n",
    "            continue\n",
    "        nar = nodes[i * 3 + j]\n",
    "        axs[i][j].plot(tmerge_df[nar].EventCount, color=cmap(0), linewidth=2, label='Twitter')\n",
    "        axs[i][j].set_ylabel('', color=cmap(0))\n",
    "        axs[i][j].tick_params(axis='y', labelcolor=cmap(0))\n",
    "\n",
    "        ax2 = axs[i][j].twinx()\n",
    "        ax2.plot(ymerge_df[nar].EventCount, color=cmap(1), linewidth=2, label='YouTube')\n",
    "        ax2.set_ylabel('', color=cmap(1))\n",
    "        ax2.tick_params(axis='y', labelcolor=cmap(1))\n",
    "\n",
    "        axs[i][j].set_title(nar)\n",
    "handles, labels = axs[2, 2].get_legend_handles_labels()\n",
    "handles2, labels2 = ax2.get_legend_handles_labels()\n",
    "fig.legend(handles + handles2, labels + labels2, loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "fig.autofmt_xdate()\n",
    "fig.suptitle(\"Time series\", fontsize=30)\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.93])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/data/leidos_extracted/2021CP5/gdelt_time_series.json', 'r') as f:\n",
    "    eventCountTimeseries = {k: pd.read_json(v, typ='series') for k, v in json.loads(f.read()).items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allnar = sorted(set(tmerge_df.keys()) | set(ymerge_df.keys())) #sorted(nodes)#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecmap = {k: i for i, k in enumerate(alleventcodes)}\n",
    "narmap = {k: i for i, k in enumerate(nodes)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tgmat = np.zeros((len(alleventcodes), len(nodes)))\n",
    "ygmat = np.zeros((len(alleventcodes), len(nodes)))\n",
    "for k1 in alleventcodes:\n",
    "    for k2 in nodes:\n",
    "        x = np.pad(np.array(eventCountTimeseries[k1].to_list()), 1, mode='constant')\n",
    "        x = x / np.linalg.norm(x)\n",
    "        y = np.array(tmerge_df[k2].EventCount.to_list())\n",
    "        if np.linalg.norm(y) > 0:\n",
    "            y = y / np.linalg.norm(y)\n",
    "        z = None\n",
    "        if k2 in ymerge_df:\n",
    "            z = np.array(ymerge_df[k2].EventCount.to_list())\n",
    "            if np.linalg.norm(z) > 0:\n",
    "                z = z / np.linalg.norm(z)\n",
    "        else:\n",
    "            z = np.array(pd.Series().reindex(idx, fill_value=0).to_list())\n",
    "        tgmat[ecmap[k1], narmap[k2]] = pearsonr(x[1:1+len(y)], y)[0]\n",
    "        ygmat[ecmap[k1], narmap[k2]] = pearsonr(x[0:0+len(z)], z)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tgmat[np.isnan(tgmat)] = -2\n",
    "ygmat[np.isnan(ygmat)] = -2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = {\n",
    "    'eventCodeMap': ecmap,\n",
    "    'narrativeMap': narmap,\n",
    "    'twitterGdeltMat': tgmat.tolist(),\n",
    "    'youtubeGdeltMat': ygmat.tolist()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(ygmat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.array(corr['youtubeGdeltMat']) == -2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/data/leidos_extracted/2021CP5/corrmat_{}.json'.format(append), 'w') as f:\n",
    "    f.write(json.dumps(corr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/data/leidos_extracted/2020CP4/corrmat{}.json'.format('_to_2_14'), 'r') as f:\n",
    "    d = json.loads(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eventCodeMap = d['eventCodeMap']\n",
    "narrativeMap = d['narrativeMap']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitterGdeltMat = np.array(corr['twitterGdeltMat'])\n",
    "twitterGdeltMat[np.array(corr['twitterGdeltMat']) == -2] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "youtubeGdeltMat = np.array(corr['youtubeGdeltMat'])\n",
    "youtubeGdeltMat[np.array(corr['youtubeGdeltMat']) == -2] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(youtubeGdeltMat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "narrativeMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.7 64-bit ('ssenv': conda)",
   "language": "python",
   "name": "python36764bitssenvconda064968db67b24473b1fc8e22de9d498f"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

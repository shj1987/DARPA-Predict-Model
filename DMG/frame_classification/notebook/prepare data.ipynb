{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "# with open('../news_text_en_phrased.json') as fin, open('WeSHClass/news_en/dataset.txt', 'w') as fout:\n",
    "#     for line in fin:\n",
    "#         js = json.loads(line)\n",
    "#         text = ((js['phrased_title'] if js['phrased_title'] else ' ') + ' ' + (js['phrased_article'] if js['phrased_article'] else ' ')).replace('\\r', ' ').replace('\\n', ' ').strip()\n",
    "#         if len(text) > 0:\n",
    "#             fout.write(text + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "children = defaultdict(set)\n",
    "nodes = set()\n",
    "for nar in narratives:\n",
    "    par = 'ROOT'\n",
    "    node = ''\n",
    "    for i in nar.split('/'):\n",
    "        if len(node) > 0:\n",
    "            node += '/'\n",
    "        node += i\n",
    "        nodes.add(node)\n",
    "        children[par].add(node)\n",
    "        par = node\n",
    "with open('WeSHClass/news_en/label_hier.txt', 'w') as fout:\n",
    "    for par in children:\n",
    "        fout.write('\\t'.join([par] + list(children[par])) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('WeSHClass/news_en/keywords.txt', 'w') as fout:\n",
    "#     for node in nodes:\n",
    "#         fout.write(node + '\\t\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "# with open('../news_text_en_phrased.json') as fin, open('WeSTClass/news_en/corpus_full.txt', 'w') as fout:\n",
    "#     for line in fin:\n",
    "#         js = json.loads(line)\n",
    "#         text = ((js['phrased_title'] if js['phrased_title'] else ' ') + ' ' + (js['phrased_article'] if js['phrased_article'] else ' ')).replace('\\r', ' ').replace('\\n', ' ').strip()\n",
    "#         if len(text) > 0:\n",
    "#             fout.write(text + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('WeSTClass/news_en/classes.txt', 'w') as fout:\n",
    "#     for idx, nar in enumerate(narratives):\n",
    "#         n = nar.split('/')[-1]\n",
    "#         fout.write(f'{idx}:{n}\\n')\n",
    "# nar2keywords = dict()\n",
    "# with open('WeSHClass/news_en/keywords.txt') as fin, open('WeSTClass/news_en/keywords.txt', 'w') as fout:\n",
    "#     for line in fin:\n",
    "#         nar, keys = line.strip().split('\\t')\n",
    "#         if nar in narratives:\n",
    "#             nar2keywords[nar] = keys.split(' ')\n",
    "#     for idx, nar in enumerate(narratives):\n",
    "#         output = ','.join(nar2keywords[nar])\n",
    "#         fout.write(f'{idx}:{output}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "url2relevance = dict()\n",
    "with open('../relevance_classification/news_relevance.json') as fin:\n",
    "    for line in fin:\n",
    "        js = json.loads(line)\n",
    "        url2relevance[js['url']] = js['relevance_prediction']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('../news_text_en_phrased.json') as fin, open('WeSTClass/news_en/corpus_title.txt', 'w') as fout, open('WeSHClass/news_en/dataset_title.txt', 'w') as fout2:\n",
    "    for line in fin:\n",
    "        js = json.loads(line)\n",
    "        text = (js['phrased_title'] if js['phrased_title'] else ' ').replace('\\r', ' ').replace('\\n', ' ').strip()\n",
    "        if len(text) > 0 and url2relevance[js['url']]:\n",
    "            fout.write(text + '\\n')\n",
    "            fout2.write(text + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# url2west_full = dict()\n",
    "# with open('../news_text_en_phrased.json') as fin, open('WeSTClass/news_en/out_full.txt') as out, open('news_text_west_result_full.json', 'w') as fout:\n",
    "#     for line in fin:\n",
    "#         js = json.loads(line)\n",
    "#         text = (js['phrased_title'] if js['phrased_title'] else ' ').replace('\\r', ' ').replace('\\n', ' ').strip()\n",
    "#         if len(text) > 0:\n",
    "#             line = out.readline().strip().split(',')\n",
    "#             assert len(narratives) == len(line)\n",
    "#             res = {nar : score for nar, score in zip(narratives, line)}\n",
    "#             js['west_score'] = res\n",
    "#             js['west_prediction'] = sorted(res, key=res.get, reverse=True)[0]\n",
    "#             url2west_full[js['url']] = js['west_prediction']\n",
    "#         fout.write(json.dumps(js) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "url2string_match = dict()\n",
    "with open('url2string_match.json') as fin:\n",
    "    for line in fin:\n",
    "        js = json.loads(line)\n",
    "#         if js['url'] in url2relevance and url2relevance[js['url']]:\n",
    "        url2string_match[js['url']] = sorted(js['string_match_score'], key=js['string_match_score'].get, reverse=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.16965162279759036\n"
     ]
    }
   ],
   "source": [
    "hit = 0\n",
    "miss = 0\n",
    "with open('../news_text_raw.json') as fin:\n",
    "    for line in fin:\n",
    "        js = json.loads(line)\n",
    "        if js['url'] in url2string_match:\n",
    "            hit += 1\n",
    "        else:\n",
    "            miss += 1\n",
    "print(hit / (hit + miss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25716\n"
     ]
    }
   ],
   "source": [
    "url2west_title = dict()\n",
    "url2title = dict()\n",
    "cnt = 0\n",
    "with open('../news_text_en_phrased.json') as fin, open('WeSTClass/news_en/out.txt') as out, open('news_text_west_result_title.json', 'w') as fout:\n",
    "    for line in fin:\n",
    "        js = json.loads(line)\n",
    "        text = (js['phrased_title'] if js['phrased_title'] else ' ').replace('\\r', ' ').replace('\\n', ' ').strip()\n",
    "        if len(text) > 0 and url2relevance[js['url']]:\n",
    "            line = out.readline().strip().split(',')\n",
    "            assert len(narratives) == len(line)\n",
    "            res = {nar : score for nar, score in zip(narratives, line)}\n",
    "            js['west_score'] = res\n",
    "            js['west_prediction'] = sorted(res, key=res.get, reverse=True)[0]\n",
    "            url2west_title[js['url']] = js['west_prediction']\n",
    "            url2title[js['url']] = js['phrased_title']\n",
    "            cnt += 1\n",
    "        fout.write(json.dumps(js) + '\\n')\n",
    "print(cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "url2bert = dict()\n",
    "with open('url2bert_prob.json') as fin:\n",
    "    for line in fin:\n",
    "        js = json.loads(line)\n",
    "        if js['url'] in url2relevance and url2relevance[js['url']]:\n",
    "            url2bert[js['url']] = sorted(js['prob'], key=js['prob'].get, reverse=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'I have lots of love for Pakistan Army,' says teenage cancer patient after meeting Gen Bajwa\n",
      "leadership/bajwa controversies/pakistan/army\n",
      "\n",
      "China Forks Out $2.4 Bln on Hydel Power Project on Pakistani Side of Kashmir Amid Tension With India - Sputnik International\n",
      "benefits/development/energy opposition/kashmir\n",
      "\n",
      "People to ignore all fake news, stories regarding jobs, projects & individuals: Chairman CPEC\n",
      "opposition/propaganda benefits/jobs\n",
      "\n",
      "Pakistani army chief calls on bilateral cooperation with Iran to ensure border security - Xinhua | English.news.cn\n",
      "leadership/bajwa controversies/china/border\n",
      "\n",
      "Pakistan army chief returns empty-handed from Saudi as Crown Prince\n",
      "controversies/pakistan/bajwa controversies/pakistan/army\n",
      "\n",
      "Defence preparation and operational readiness to ensure peace: Gen Bajwa\n",
      "leadership/bajwa controversies/pakistan/bajwa\n",
      "\n",
      "Army chief lauds Pakistan Navy for its sacrifice and valour\n",
      "leadership/bajwa controversies/china/naval\n",
      "\n",
      "Gen Bajwa says Pak Army will respond with full might if provoked\n",
      "leadership/bajwa controversies/pakistan/bajwa\n",
      "\n",
      "42 60 0.7\n",
      "0.8095238095238095\n",
      "controversies/pakistan/students 0\n",
      "leadership/sharif 0\n",
      "leadership/bajwa 10\n",
      "controversies/china/uighur 10\n",
      "controversies/china/border 10\n",
      "benefits/development/roads 2\n",
      "controversies/pakistan/baloch 10\n",
      "benefits/jobs 2\n",
      "opposition/propaganda 5\n",
      "benefits/development/energy 7\n",
      "controversies/pakistan/bajwa 4\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "hit = 0\n",
    "miss = 0\n",
    "selected_nar = ['controversies/pakistan/students', 'leadership/sharif', 'leadership/bajwa', 'controversies/china/uighur', 'controversies/china/border', 'benefits/development/roads', 'controversies/pakistan/baloch', 'benefits/jobs', 'opposition/propaganda', 'benefits/development/energy', 'controversies/pakistan/bajwa']\n",
    "from collections import defaultdict\n",
    "target = url2string_match\n",
    "hit_nar = defaultdict(int)\n",
    "miss_nar = defaultdict(int)\n",
    "cnt_nar = defaultdict(int)\n",
    "total = 0\n",
    "with open('../cp5_test.csv') as fin:\n",
    "    reader = csv.DictReader(fin, delimiter=',')\n",
    "    for js in reader:\n",
    "        label = js['frame']\n",
    "        total += 1\n",
    "        cnt_nar[label] += 1\n",
    "        if js['url'] in target:\n",
    "            pred = target[js['url']]\n",
    "            if pred == label:\n",
    "                hit += 1\n",
    "                hit_nar[label] += 1\n",
    "            else:\n",
    "                miss += 1\n",
    "                miss_nar[label] += 1\n",
    "#                 print(label)\n",
    "                print(js['title'])\n",
    "                print(label, pred)\n",
    "                print()\n",
    "print(hit + miss, total, (hit + miss) / total)\n",
    "print(hit / (hit + miss))\n",
    "for nar in selected_nar:\n",
    "    print(nar, cnt_nar[nar])\n",
    "#     print(nar, hit_nar[nar] / (hit_nar[nar] + miss_nar[nar]) if (hit_nar[nar] + miss_nar[nar]) > 0 else -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.08061939289664495\n",
      "0.7538109756097561\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "hit = 0\n",
    "miss = 0\n",
    "target = url2string_match\n",
    "total = 0\n",
    "with open('../url2tweet_frame.json') as fin:\n",
    "    for line in fin:\n",
    "        js = json.loads(line)\n",
    "        if len(js['frames']) == 0:\n",
    "            continue\n",
    "        total += 1\n",
    "        label = js['frames'][0]\n",
    "        if js['url'] in target:\n",
    "            pred = target[js['url']]\n",
    "            if pred == label:\n",
    "                hit += 1\n",
    "            else:\n",
    "                miss += 1\n",
    "#                 print(label)\n",
    "#                 print(url2title[js['url']])\n",
    "#                 print(label, pred)\n",
    "#                 print()\n",
    "print((hit + miss)/total)\n",
    "print(hit / (hit + miss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "benefits/connections/afghanistan 31 55\n",
      "benefits/covid 340 780\n",
      "benefits/development/energy 91 164\n",
      "benefits/development/maritime 81 151\n",
      "benefits/development/roads 61 173\n",
      "benefits/jobs 50 82\n",
      "controversies/china/border 1473 2806\n",
      "controversies/china/debt 77 143\n",
      "controversies/china/exploitation 36 74\n",
      "controversies/china/funding 10 14\n",
      "controversies/china/naval 0 4\n",
      "controversies/china/uighur 27 37\n",
      "controversies/pakistan/army 22 33\n",
      "controversies/pakistan/bajwa 5 5\n",
      "controversies/pakistan/baloch 78 127\n",
      "controversies/pakistan/students 8 16\n",
      "leadership/bajwa 64 104\n",
      "leadership/khan 232 603\n",
      "leadership/sharif 24 52\n",
      "opposition/kashmir 148 345\n",
      "opposition/propaganda 49 76\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from collections import defaultdict\n",
    "en_url = set()\n",
    "raw_url = set()\n",
    "with open('../news_text_en_phrased.json') as fin:\n",
    "    for line in fin:\n",
    "        js = json.loads(line)\n",
    "        en_url.add(js['url'])\n",
    "raw_url = set()\n",
    "with open('../news_text_raw.json') as fin:\n",
    "    for line in fin:\n",
    "        js = json.loads(line)\n",
    "        raw_url.add(js['url'])\n",
    "raw_cnt = defaultdict(int)\n",
    "en_cnt = defaultdict(int)\n",
    "with open('../url2tweet_frame.json') as fin:\n",
    "    for line in fin:\n",
    "        js = json.loads(line)\n",
    "        if len(js['frames']) == 0:\n",
    "            continue\n",
    "        for f in js['frames']:\n",
    "            if js['url'] in en_url:\n",
    "                en_cnt[f] += 1\n",
    "            if js['url'] in raw_url:\n",
    "                raw_cnt[f] += 1\n",
    "for n in narratives:\n",
    "    print(n, en_cnt[n], raw_cnt[n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "afghanistan : afghanistan, afghan, kabul, taliban\n",
      "covid : covid, covid-19, coronavirus, covid_19, pandemic, covid19, cases_rise, lockdown\n",
      "energy : renewable, renewables, energy_consumption, renewable_energy, power_generation, coal_expansion, energy_projects\n",
      "maritime : maritime, indian_ocean, vessels, coast, maritime_security, fleet, naval, indo_-_pacific, coast_guard, coastal, maritime_domain, south_china_sea, arabian_sea\n",
      "roads : mortal_way, expressway, highway, underpass\n",
      "jobs : employment, jobs, unemployment, lose_jobs, unemployed\n",
      "border : india_china_border_conflict, siachen_glacier, karakoram_pass, border, casualties, borders, frontier, lac, crossing, sikkim, line_of_actual_control\n",
      "debt : debt, expense, debts, repayments, lending, debt_relief, repayment, external_debt, borrowing, loans\n",
      "exploitation : exploitation, repression, oppression, exploiting, rampant, fundamental_rights, impunity, marginalisation, suppress, suppression\n",
      "funding : funded, funding, funded_by, financial_support, funds, financing, invested, investments\n",
      "naval : fleet, naval, warships, navy, submarines, ships, squadron, submarine, aircraft_carriers, warship\n",
      "uighur : uighur, uyghur, uighurs, uighur_muslims, uighur_families, minority, xinjiang, tibetan, forced_labor\n",
      "pakistan_army : pakistan_army, pakistani_army\n",
      "bajwa : gen_bajwa, qamar_javed_bajwa, gen_qamar_javed_bajwa, appointed_information_minister, special_assistant_to_pm_on_information, corruption, scandals\n",
      "baloch : baloch, balochistan, balochi, baluch, gichak_valley, baloch_liberation_army, claimed_responsibility, balochistan_national_party\n",
      "students : online_classes, pakistani_students, baloch_student, exam_cancellation\n",
      "bajwa : gen_bajwa, qamar_javed_bajwa, gen_qamar_javed_bajwa, appointed_information_minister, special_assistant_to_pm_on_information, corruption, scandals\n",
      "imran_khan : imran_khan, prime_minister_of_pakistan, pm_imran\n",
      "sharif : shehbaz_sharif, shahbaz_sharif, nawaz_sharif, sharif_family, corruption_case, extradition_case, extradition\n",
      "kashmir : kashmir, kashmir_region, kashmir_valley\n",
      "propaganda : disinformation, propaganda, information_warfare, fake_news, misleading, mislead, false_propaganda, political_absurdity\n"
     ]
    }
   ],
   "source": [
    "with open('WeSTClass/news_en/classes.txt') as fin, open('WeSTClass/news_en/keywords.txt') as fin2:\n",
    "    for line1, line2 in zip(fin, fin2):\n",
    "        cat = line1.strip().split(':')[1]\n",
    "        keys = line2.strip().split(':')[1].split(',')\n",
    "        print(cat + ' : ' + ', '.join(keys))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

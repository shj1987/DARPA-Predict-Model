{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dates for the competition period\n",
    "cor_end_date = \"2020-08-03\"\n",
    "cor_end_date2 = \"8_03\"\n",
    "series_end_date = \"8_31\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp5_home=\"/home/qiuwenda/CP5/cleaned/\"\n",
    "cp5_py=\"/home/qiuwenda/anaconda3/envs/pytorch/bin/python\"\n",
    "cp5_ipy=\"/home/qiuwenda/anaconda3/envs/pytorch/bin/ipython\"\n",
    "# Please also update frame_classification/LeidosBERT/run_bert.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5276it [00:00, 8123.31it/s]\n",
      "339876\n",
      "21\n",
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
      "100%|████████████████████████████████████| 5276/5276 [00:00<00:00, 84330.11it/s]\n",
      "100%|████████████████████████████████████| 5276/5276 [00:00<00:00, 32235.54it/s]\n",
      "2021-06-13 11:35:09.498160: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "100%|█████████████████████████████████████| 5276/5276 [00:01<00:00, 3215.11it/s]\n",
      "100%|██████████████████████████████████| 1533/1533 [00:00<00:00, 1521142.19it/s]\n",
      "100%|█████████████████████████████████████| 1350/1350 [00:00<00:00, 8951.51it/s]\n",
      "100%|███████████████████████████████████████| 1350/1350 [03:08<00:00,  7.15it/s]\n",
      "error rate: 0.6793025018953753\n",
      "#phrases 155576\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing: cleaning\n",
    "!cd $cp5_home && $cp5_py clean_text_append.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing: relevance classification \n",
    "# !cd $cp5_home/relevance_classification/ && $cp5_py relevance_append.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11532477635161416\r\n"
     ]
    }
   ],
   "source": [
    "# Classification: string match\n",
    "!cd $cp5_home/frame_classification/ && $cp5_py string_match_append.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-06-13 11:38:32.946301: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "Namespace(dir='cpec_frame', input='data/input_append.csv', model='cpec_frame.bin', output='data/output_append.csv', type='frame')\n",
      "/home/qiuwenda/anaconda3/envs/dpr/lib/python3.8/site-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 804: forward compatibility was attempted on non supported HW (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:100.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n",
      "06/13/2021 11:38:33 - INFO - __main__ -   device: cpu n_gpu: 0, distributed training: False, 16-bits training: False\n",
      "['benefits/connections/afghanistan', 'benefits/covid', 'benefits/development/energy', 'benefits/development/maritime', 'benefits/development/roads', 'benefits/jobs', 'controversies/china/border', 'controversies/china/debt', 'controversies/china/exploitation', 'controversies/china/funding', 'controversies/china/naval', 'controversies/china/uighur', 'controversies/pakistan/army', 'controversies/pakistan/bajwa', 'controversies/pakistan/baloch', 'controversies/pakistan/students', 'leadership/bajwa', 'leadership/khan', 'leadership/sharif', 'opposition/kashmir', 'opposition/propaganda']\n",
      "21\n",
      "06/13/2021 11:38:36 - INFO - transformers.tokenization_utils_base -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-cased-vocab.txt from cache at /home/qiuwenda/.cache/torch/transformers/96435fa287fbf7e469185f1062386e05a075cadbf6838b74da22bf64b080bc32.99bcd55fc66f4f3360bc49ba472b940b8dcf223ea6a345deb969d607ca900729\n",
      "21\n",
      "06/13/2021 11:38:38 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-cased-config.json from cache at /home/qiuwenda/.cache/torch/transformers/45629519f3117b89d89fd9c740073d8e4c1f0a70f9842476185100a8afe715d1.65df3cef028a0c91a7b059e4c404a975ebe6843c71267b67019c0e9cfa8a88f0\n",
      "06/13/2021 11:38:38 - INFO - transformers.configuration_utils -   Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\",\n",
      "    \"3\": \"LABEL_3\",\n",
      "    \"4\": \"LABEL_4\",\n",
      "    \"5\": \"LABEL_5\",\n",
      "    \"6\": \"LABEL_6\",\n",
      "    \"7\": \"LABEL_7\",\n",
      "    \"8\": \"LABEL_8\",\n",
      "    \"9\": \"LABEL_9\",\n",
      "    \"10\": \"LABEL_10\",\n",
      "    \"11\": \"LABEL_11\",\n",
      "    \"12\": \"LABEL_12\",\n",
      "    \"13\": \"LABEL_13\",\n",
      "    \"14\": \"LABEL_14\",\n",
      "    \"15\": \"LABEL_15\",\n",
      "    \"16\": \"LABEL_16\",\n",
      "    \"17\": \"LABEL_17\",\n",
      "    \"18\": \"LABEL_18\",\n",
      "    \"19\": \"LABEL_19\",\n",
      "    \"20\": \"LABEL_20\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_10\": 10,\n",
      "    \"LABEL_11\": 11,\n",
      "    \"LABEL_12\": 12,\n",
      "    \"LABEL_13\": 13,\n",
      "    \"LABEL_14\": 14,\n",
      "    \"LABEL_15\": 15,\n",
      "    \"LABEL_16\": 16,\n",
      "    \"LABEL_17\": 17,\n",
      "    \"LABEL_18\": 18,\n",
      "    \"LABEL_19\": 19,\n",
      "    \"LABEL_2\": 2,\n",
      "    \"LABEL_20\": 20,\n",
      "    \"LABEL_3\": 3,\n",
      "    \"LABEL_4\": 4,\n",
      "    \"LABEL_5\": 5,\n",
      "    \"LABEL_6\": 6,\n",
      "    \"LABEL_7\": 7,\n",
      "    \"LABEL_8\": 8,\n",
      "    \"LABEL_9\": 9\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 119547\n",
      "}\n",
      "\n",
      "06/13/2021 11:38:41 - INFO - filelock -   Lock 140524341477632 acquired on /home/qiuwenda/.cache/torch/transformers/3d1d2b2daef1e2b3ddc2180ddaae8b7a37d5f279babce0068361f71cd548f615.7131dcb754361639a7d5526985f880879c9bfd144b65a0bf50590bddb7de9059.lock\n",
      "06/13/2021 11:38:41 - INFO - transformers.file_utils -   https://cdn.huggingface.co/bert-base-multilingual-cased-pytorch_model.bin not found in cache or force_download set to True, downloading to /home/qiuwenda/.cache/torch/transformers/tmpm56kspb0\n",
      "Downloading: 100%|███████████████████████████| 714M/714M [02:47<00:00, 4.27MB/s]\n",
      "06/13/2021 11:41:30 - INFO - transformers.file_utils -   storing https://cdn.huggingface.co/bert-base-multilingual-cased-pytorch_model.bin in cache at /home/qiuwenda/.cache/torch/transformers/3d1d2b2daef1e2b3ddc2180ddaae8b7a37d5f279babce0068361f71cd548f615.7131dcb754361639a7d5526985f880879c9bfd144b65a0bf50590bddb7de9059\n",
      "06/13/2021 11:41:30 - INFO - transformers.file_utils -   creating metadata file for /home/qiuwenda/.cache/torch/transformers/3d1d2b2daef1e2b3ddc2180ddaae8b7a37d5f279babce0068361f71cd548f615.7131dcb754361639a7d5526985f880879c9bfd144b65a0bf50590bddb7de9059\n",
      "06/13/2021 11:41:30 - INFO - filelock -   Lock 140524341477632 released on /home/qiuwenda/.cache/torch/transformers/3d1d2b2daef1e2b3ddc2180ddaae8b7a37d5f279babce0068361f71cd548f615.7131dcb754361639a7d5526985f880879c9bfd144b65a0bf50590bddb7de9059.lock\n",
      "06/13/2021 11:41:30 - INFO - transformers.modeling_utils -   loading weights file https://cdn.huggingface.co/bert-base-multilingual-cased-pytorch_model.bin from cache at /home/qiuwenda/.cache/torch/transformers/3d1d2b2daef1e2b3ddc2180ddaae8b7a37d5f279babce0068361f71cd548f615.7131dcb754361639a7d5526985f880879c9bfd144b65a0bf50590bddb7de9059\n",
      "06/13/2021 11:41:34 - WARNING - transformers.modeling_utils -   Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForMultiLabelSequenceClassification: ['bert.embeddings.position_ids']\n",
      "- This IS expected if you are initializing BertForMultiLabelSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing BertForMultiLabelSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "06/13/2021 11:41:34 - INFO - transformers.modeling_utils -   All the weights of BertForMultiLabelSequenceClassification were initialized from the model checkpoint at bert-base-multilingual-cased.\n",
      "If your task is similar to the task the model of the ckeckpoint was trained on, you can already use BertForMultiLabelSequenceClassification for predictions without further training.\n",
      "06/13/2021 11:42:05 - INFO - __main__ -   ***** Running prediction *****\n",
      "06/13/2021 11:42:05 - INFO - __main__ -     Num examples = 2949\n",
      "06/13/2021 11:42:05 - INFO - __main__ -     Batch size = 32\n",
      "Prediction Iteration: 100%|█████████████████████| 93/93 [00:37<00:00,  2.48it/s]\n",
      "        id  ... opposition/propaganda\n",
      "0        1  ...              0.000894\n",
      "1        3  ...              0.019482\n",
      "2        5  ...              0.006241\n",
      "3        6  ...              0.002227\n",
      "4        7  ...              0.005080\n",
      "...    ...  ...                   ...\n",
      "2944  5245  ...              0.000969\n",
      "2945  5248  ...              0.000812\n",
      "2946  5249  ...              0.007455\n",
      "2947  5259  ...              0.002281\n",
      "2948  5261  ...              0.000709\n",
      "\n",
      "[2949 rows x 23 columns]\n",
      "\u001b[22;0t\u001b]0;IPython: frame_classification/LeidosBERT\u0007"
     ]
    }
   ],
   "source": [
    "# Classification: LEIDOS BERT\n",
    "!cd $cp5_home/frame_classification/LeidosBERT/ && $cp5_ipy leidos_bert_append.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[22;0t\u001b]0;IPython: CP5/cleaned\u0007['news_text_en_phrased.json', 'news_text_en_phrased_append.json']\n",
      "2021-06-13 11:57:25.189077: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "/home/qiuwenda/anaconda3/envs/west/lib/python3.8/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.cluster.k_means_ module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.cluster. Anything that cannot be imported from sklearn.cluster is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/home/qiuwenda/anaconda3/envs/west/lib/python3.8/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "Namespace(alpha=0.2, batch_size=256, beta=500, dataset='news_manual', delta=0.1, gamma=50, maxiter=5000, model='cnn', pretrain_epochs=None, sup_source='keywords', trained_weights=None, update_interval=None, with_evaluation='False')\n",
      "\n",
      "### Dataset statistics: ###\n",
      "Document max length: 554 (words)\n",
      "Document average length: 346.6034226190476 (words)\n",
      "Document length std: 149.00720965762812 (words)\n",
      "Defined maximum document length: 500 (words)\n",
      "Fraction of truncated documents: 0.001488095238095238\n",
      "Vocabulary Size: 40000\n",
      "\n",
      "### Supervision type: Class-related Keywords ###\n",
      "Keywords for each class: \n",
      "Supervision content of class 0:\n",
      "['gen_bajwa', 'qamar_javed_bajwa', 'gen_qamar_javed_bajwa']\n",
      "Supervision content of class 1:\n",
      "['baloch', 'balochistan', 'balochi', 'baluch']\n",
      "Supervision content of class 2:\n",
      "['win-win', 'benefit', 'benefits']\n",
      "Supervision content of class 3:\n",
      "['siachen_glacier', 'karakoram_pass', 'boundary', 'borders', 'frontier', 'indo', 'along', 'lac', 'crossing', 'sikkim', 'line_of_actual_control']\n",
      "Supervision content of class 4:\n",
      "['china', 'beijing', 'chinese', 'xi', 'taiwan', 'xi_jinping', 'chinas']\n",
      "Supervision content of class 5:\n",
      "['backlash_against', 'controversy', 'rumors', 'rumours', 'speculation', 'backlash', 'bizarre_claim', 'conspiracy_theories', 'fake_news']\n",
      "Supervision content of class 6:\n",
      "['construction', 'development', 'projects']\n",
      "Supervision content of class 7:\n",
      "['dam', 'petroleum', 'gas', 'oil', 'natural_gas', 'power_generation', 'renewable_energy', 'clean_energy', 'crude_oil', 'fertilizer', 'mining']\n",
      "Supervision content of class 8:\n",
      "['employment', 'jobs', 'pakistan']\n",
      "Supervision content of class 9:\n",
      "['coalition', 'alliance', 'leader', 'factions', 'political', 'leaders', 'party', 'supporters']\n",
      "Supervision content of class 10:\n",
      "['opposition_leader', 'opposition_parties']\n",
      "Supervision content of class 11:\n",
      "['pakistan', 'pak', 'pm_imran', 'imran_khan', 'islamabad', 'pakistani']\n",
      "Supervision content of class 12:\n",
      "['propaganda', 'disinformation', 'fake_news', 'misinformation', 'false_information']\n",
      "Supervision content of class 13:\n",
      "['underpasses', 'underpass', 'mortal_way', 'expressway', 'bridge', 'bridges']\n",
      "Supervision content of class 14:\n",
      "['shehbaz_sharif', 'shahbaz_sharif', 'nawaz_sharif']\n",
      "Supervision content of class 15:\n",
      "['students', 'online_classes', 'classes', 'university', 'universities', 'school', 'schools', 'classmates']\n",
      "Supervision content of class 16:\n",
      "['uighurs', 'uyghur', 'uyghurs', 'xinjiang', 'minority', 'racial', 'discrimination']\n",
      "\n",
      "### Input preparation ###\n",
      "Training Word2Vec model...\n",
      "Model: skip-gram\n",
      "Saving Word2Vec model ./news_manual/embedding\n",
      "main.py:46: DeprecationWarning: Call to deprecated `__contains__` (Method will be removed in 4.0.0, use self.wv.__contains__() instead).\n",
      "  embedding_weights = {key: embedding_model[word] if word in embedding_model else\n",
      "main.py:46: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  embedding_weights = {key: embedding_model[word] if word in embedding_model else\n",
      "2021-06-13 11:57:30.212803: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2021-06-13 11:57:30.213746: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2021-06-13 11:57:30.236700: E tensorflow/stream_executor/cuda/cuda_driver.cc:328] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2021-06-13 11:57:30.236720: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: qiuwenda-Station\n",
      "2021-06-13 11:57:30.236727: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: qiuwenda-Station\n",
      "2021-06-13 11:57:30.236894: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 460.84.0\n",
      "2021-06-13 11:57:30.236910: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 460.80.0\n",
      "2021-06-13 11:57:30.236914: E tensorflow/stream_executor/cuda/cuda_diagnostics.cc:313] kernel version 460.80.0 does not match DSO version 460.84.0 -- cannot find working devices in this configuration\n",
      "2021-06-13 11:57:30.241250: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "\n",
      "### Phase 1: vMF distribution fitting & pseudo document generation ###\n",
      "main.py:209: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  word_sup_array = np.array([np.array([vocabulary[word] for word in word_class_list if word in vocabulary]) for word_class_list in word_sup_list])\n",
      "Retrieving top-t nearest words...\n",
      "Final expansion size t = 1\n",
      "Top-t nearest words for each class:\n",
      "Class 0:\n",
      "['qamar_javed_bajwa']\n",
      "/home/qiuwenda/anaconda3/envs/west/lib/python3.8/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.cluster.k_means_ module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.cluster. Anything that cannot be imported from sklearn.cluster is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/home/qiuwenda/anaconda3/envs/west/lib/python3.8/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/qiuwenda/anaconda3/envs/west/lib/python3.8/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.cluster.k_means_ module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.cluster. Anything that cannot be imported from sklearn.cluster is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/home/qiuwenda/anaconda3/envs/west/lib/python3.8/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/qiuwenda/anaconda3/envs/west/lib/python3.8/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.cluster.k_means_ module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.cluster. Anything that cannot be imported from sklearn.cluster is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/home/qiuwenda/anaconda3/envs/west/lib/python3.8/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/qiuwenda/anaconda3/envs/west/lib/python3.8/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.cluster.k_means_ module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.cluster. Anything that cannot be imported from sklearn.cluster is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/home/qiuwenda/anaconda3/envs/west/lib/python3.8/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.cluster.k_means_ module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.cluster. Anything that cannot be imported from sklearn.cluster is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/home/qiuwenda/anaconda3/envs/west/lib/python3.8/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/qiuwenda/anaconda3/envs/west/lib/python3.8/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/qiuwenda/anaconda3/envs/west/lib/python3.8/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.cluster.k_means_ module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.cluster. Anything that cannot be imported from sklearn.cluster is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/home/qiuwenda/anaconda3/envs/west/lib/python3.8/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/qiuwenda/anaconda3/envs/west/lib/python3.8/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.cluster.k_means_ module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.cluster. Anything that cannot be imported from sklearn.cluster is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/home/qiuwenda/anaconda3/envs/west/lib/python3.8/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/qiuwenda/anaconda3/envs/west/lib/python3.8/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.cluster.k_means_ module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.cluster. Anything that cannot be imported from sklearn.cluster is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/home/qiuwenda/anaconda3/envs/west/lib/python3.8/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/qiuwenda/anaconda3/envs/west/lib/python3.8/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.cluster.k_means_ module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.cluster. Anything that cannot be imported from sklearn.cluster is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/home/qiuwenda/anaconda3/envs/west/lib/python3.8/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/qiuwenda/anaconda3/envs/west/lib/python3.8/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.cluster.k_means_ module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.cluster. Anything that cannot be imported from sklearn.cluster is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/home/qiuwenda/anaconda3/envs/west/lib/python3.8/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 1:\n",
      "['baloch', 'balochistan', 'balochi']\n",
      "/home/qiuwenda/anaconda3/envs/west/lib/python3.8/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.cluster.k_means_ module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.cluster. Anything that cannot be imported from sklearn.cluster is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/home/qiuwenda/anaconda3/envs/west/lib/python3.8/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/qiuwenda/anaconda3/envs/west/lib/python3.8/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.cluster.k_means_ module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.cluster. Anything that cannot be imported from sklearn.cluster is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/home/qiuwenda/anaconda3/envs/west/lib/python3.8/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/qiuwenda/anaconda3/envs/west/lib/python3.8/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.cluster.k_means_ module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.cluster. Anything that cannot be imported from sklearn.cluster is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/home/qiuwenda/anaconda3/envs/west/lib/python3.8/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/qiuwenda/anaconda3/envs/west/lib/python3.8/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.cluster.k_means_ module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.cluster. Anything that cannot be imported from sklearn.cluster is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/home/qiuwenda/anaconda3/envs/west/lib/python3.8/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/qiuwenda/anaconda3/envs/west/lib/python3.8/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.cluster.k_means_ module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.cluster. Anything that cannot be imported from sklearn.cluster is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/home/qiuwenda/anaconda3/envs/west/lib/python3.8/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "Class 2:\n",
      "['benefit', 'benefits']\n",
      "Class 3:\n",
      "['siachen_glacier', 'karakoram_pass', 'boundary', 'borders', 'frontier', 'indo', 'along', 'lac', 'crossing', 'sikkim', 'line_of_actual_control']\n",
      "Class 4:\n",
      "['china', 'beijing', 'chinese', 'xi', 'taiwan', 'xi_jinping', 'chinas']\n",
      "Class 5:\n",
      "['controversy', 'rumors', 'rumours', 'speculation', 'backlash', 'conspiracy_theories', 'fake_news']\n",
      "Class 6:\n",
      "['construction', 'development', 'projects']\n",
      "Class 7:\n",
      "['dam', 'petroleum', 'gas', 'oil', 'natural_gas', 'power_generation', 'renewable_energy', 'clean_energy', 'crude_oil', 'fertilizer', 'mining']\n",
      "Class 8:\n",
      "['employment', 'jobs', 'pakistan']\n",
      "Class 9:\n",
      "['coalition', 'alliance', 'leader', 'factions', 'political', 'leaders', 'party', 'supporters']\n",
      "Class 10:\n",
      "['opposition_parties']\n",
      "Class 11:\n",
      "['pakistan', 'pak', 'pm_imran', 'imran_khan', 'islamabad', 'pakistani']\n",
      "Class 12:\n",
      "['propaganda', 'disinformation', 'fake_news', 'misinformation', 'false_information']\n",
      "Class 13:\n",
      "['underpasses', 'underpass', 'expressway', 'bridge', 'bridges']\n",
      "Class 14:\n",
      "['shehbaz_sharif', 'shahbaz_sharif', 'nawaz_sharif']\n",
      "Class 15:\n",
      "['students', 'online_classes', 'classes', 'university', 'universities', 'school', 'schools', 'classmates']\n",
      "Class 16:\n",
      "['uighurs', 'uyghur', 'uyghurs', 'xinjiang', 'minority', 'racial', 'discrimination']\n",
      "Finished vMF distribution fitting.\n",
      "Pseudo documents generation...\n",
      "Finished Pseudo documents generation.\n",
      "\n",
      "### Phase 2: pre-training with pseudo documents ###\n",
      "\n",
      "Neural model summary: \n",
      "Model: \"classifier\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input (InputLayer)              [(None, 500)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 500, 100)     4000000     input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 499, 20)      4020        embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 498, 20)      6020        embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 497, 20)      8020        embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 496, 20)      10020       embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d (GlobalMax (None, 20)           0           conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_1 (GlobalM (None, 20)           0           conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_2 (GlobalM (None, 20)           0           conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_3 (GlobalM (None, 20)           0           conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 80)           0           global_max_pooling1d[0][0]       \n",
      "                                                                 global_max_pooling1d_1[0][0]     \n",
      "                                                                 global_max_pooling1d_2[0][0]     \n",
      "                                                                 global_max_pooling1d_3[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 20)           1620        concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 17)           357         dense[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 4,030,057\n",
      "Trainable params: 30,057\n",
      "Non-trainable params: 4,000,000\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "Pretraining...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-06-13 11:58:03.105221: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2021-06-13 11:58:03.124011: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2894645000 Hz\n",
      "Epoch 1/30\n",
      "34/34 [==============================] - 3s 69ms/step - loss: 1.8145\n",
      "Epoch 2/30\n",
      "34/34 [==============================] - 2s 68ms/step - loss: 1.5655\n",
      "Epoch 3/30\n",
      "34/34 [==============================] - 2s 69ms/step - loss: 0.9302\n",
      "Epoch 4/30\n",
      "34/34 [==============================] - 2s 69ms/step - loss: 0.7295\n",
      "Epoch 5/30\n",
      "34/34 [==============================] - 2s 69ms/step - loss: 0.5990\n",
      "Epoch 6/30\n",
      "34/34 [==============================] - 2s 69ms/step - loss: 0.5348\n",
      "Epoch 7/30\n",
      "34/34 [==============================] - 2s 69ms/step - loss: 0.4984\n",
      "Epoch 8/30\n",
      "34/34 [==============================] - 2s 69ms/step - loss: 0.4419\n",
      "Epoch 9/30\n",
      "34/34 [==============================] - 2s 69ms/step - loss: 0.4179\n",
      "Epoch 10/30\n",
      "34/34 [==============================] - 2s 69ms/step - loss: 0.3881\n",
      "Epoch 11/30\n",
      "34/34 [==============================] - 2s 69ms/step - loss: 0.3645\n",
      "Epoch 12/30\n",
      "34/34 [==============================] - 2s 69ms/step - loss: 0.3248\n",
      "Epoch 13/30\n",
      "34/34 [==============================] - 2s 70ms/step - loss: 0.3020\n",
      "Epoch 14/30\n",
      "34/34 [==============================] - 2s 69ms/step - loss: 0.2805\n",
      "Epoch 15/30\n",
      "34/34 [==============================] - 2s 69ms/step - loss: 0.2640\n",
      "Epoch 16/30\n",
      "34/34 [==============================] - 2s 69ms/step - loss: 0.2594\n",
      "Epoch 17/30\n",
      "34/34 [==============================] - 2s 69ms/step - loss: 0.2388\n",
      "Epoch 18/30\n",
      "34/34 [==============================] - 2s 69ms/step - loss: 0.2180\n",
      "Epoch 19/30\n",
      "34/34 [==============================] - 2s 69ms/step - loss: 0.2191\n",
      "Epoch 20/30\n",
      "34/34 [==============================] - 2s 69ms/step - loss: 0.2002\n",
      "Epoch 21/30\n",
      "34/34 [==============================] - 2s 70ms/step - loss: 0.1932\n",
      "Epoch 22/30\n",
      "34/34 [==============================] - 2s 69ms/step - loss: 0.1839\n",
      "Epoch 23/30\n",
      "34/34 [==============================] - 2s 69ms/step - loss: 0.1803\n",
      "Epoch 24/30\n",
      "34/34 [==============================] - 2s 70ms/step - loss: 0.1710\n",
      "Epoch 25/30\n",
      "34/34 [==============================] - 2s 69ms/step - loss: 0.1619\n",
      "Epoch 26/30\n",
      "34/34 [==============================] - 2s 69ms/step - loss: 0.1584\n",
      "Epoch 27/30\n",
      "34/34 [==============================] - 2s 69ms/step - loss: 0.1479\n",
      "Epoch 28/30\n",
      "34/34 [==============================] - 2s 69ms/step - loss: 0.1601\n",
      "Epoch 29/30\n",
      "34/34 [==============================] - 2s 69ms/step - loss: 0.1481\n",
      "Epoch 30/30\n",
      "34/34 [==============================] - 2s 69ms/step - loss: 0.1459\n",
      "Pretraining time: 71.14s\n",
      "Pretrained model saved to ./results/news_manual/cnn/phase2/pretrained.h5\n",
      "\n",
      "### Phase 3: self-training ###\n",
      "Update interval: 50\n",
      "\n",
      "Iter 0: Fraction of documents with label changes: 0.0 %\n",
      "\n",
      "Iter 50: Fraction of documents with label changes: 5.283 %\n",
      "\n",
      "Iter 100: Fraction of documents with label changes: 4.688 %\n",
      "\n",
      "Iter 150: Fraction of documents with label changes: 4.39 %\n",
      "\n",
      "Iter 200: Fraction of documents with label changes: 4.836 %\n",
      "\n",
      "Iter 250: Fraction of documents with label changes: 4.464 %\n",
      "\n",
      "Iter 300: Fraction of documents with label changes: 4.836 %\n",
      "\n",
      "Iter 350: Fraction of documents with label changes: 3.869 %\n",
      "\n",
      "Iter 400: Fraction of documents with label changes: 3.795 %\n",
      "\n",
      "Iter 450: Fraction of documents with label changes: 3.423 %\n",
      "\n",
      "Iter 500: Fraction of documents with label changes: 2.679 %\n",
      "\n",
      "Iter 550: Fraction of documents with label changes: 2.902 %\n",
      "\n",
      "Iter 600: Fraction of documents with label changes: 3.274 %\n",
      "\n",
      "Iter 650: Fraction of documents with label changes: 2.902 %\n",
      "\n",
      "Iter 700: Fraction of documents with label changes: 2.455 %\n",
      "\n",
      "Iter 750: Fraction of documents with label changes: 2.679 %\n",
      "\n",
      "Iter 800: Fraction of documents with label changes: 2.976 %\n",
      "\n",
      "Iter 850: Fraction of documents with label changes: 2.976 %\n",
      "\n",
      "Iter 900: Fraction of documents with label changes: 2.604 %\n",
      "\n",
      "Iter 950: Fraction of documents with label changes: 2.307 %\n",
      "\n",
      "Iter 1000: Fraction of documents with label changes: 1.786 %\n",
      "\n",
      "Iter 1050: Fraction of documents with label changes: 2.679 %\n",
      "\n",
      "Iter 1100: Fraction of documents with label changes: 2.902 %\n",
      "\n",
      "Iter 1150: Fraction of documents with label changes: 2.455 %\n",
      "\n",
      "Iter 1200: Fraction of documents with label changes: 1.935 %\n",
      "\n",
      "Iter 1250: Fraction of documents with label changes: 1.711 %\n",
      "\n",
      "Iter 1300: Fraction of documents with label changes: 2.455 %\n",
      "\n",
      "Iter 1350: Fraction of documents with label changes: 1.935 %\n",
      "\n",
      "Iter 1400: Fraction of documents with label changes: 1.935 %\n",
      "\n",
      "Iter 1450: Fraction of documents with label changes: 1.711 %\n",
      "\n",
      "Iter 1500: Fraction of documents with label changes: 1.488 %\n",
      "\n",
      "Iter 1550: Fraction of documents with label changes: 1.562 %\n",
      "\n",
      "Iter 1600: Fraction of documents with label changes: 1.488 %\n",
      "\n",
      "Iter 1650: Fraction of documents with label changes: 0.818 %\n",
      "\n",
      "Iter 1700: Fraction of documents with label changes: 1.488 %\n",
      "\n",
      "Iter 1750: Fraction of documents with label changes: 1.637 %\n",
      "\n",
      "Iter 1800: Fraction of documents with label changes: 0.893 %\n",
      "\n",
      "Iter 1850: Fraction of documents with label changes: 1.042 %\n",
      "\n",
      "Iter 1900: Fraction of documents with label changes: 1.711 %\n",
      "\n",
      "Iter 1950: Fraction of documents with label changes: 1.19 %\n",
      "\n",
      "Iter 2000: Fraction of documents with label changes: 1.265 %\n",
      "\n",
      "Iter 2050: Fraction of documents with label changes: 0.893 %\n",
      "\n",
      "Iter 2100: Fraction of documents with label changes: 0.818 %\n",
      "\n",
      "Iter 2150: Fraction of documents with label changes: 1.116 %\n",
      "\n",
      "Iter 2200: Fraction of documents with label changes: 1.116 %\n",
      "\n",
      "Iter 2250: Fraction of documents with label changes: 1.339 %\n",
      "\n",
      "Iter 2300: Fraction of documents with label changes: 0.67 %\n",
      "\n",
      "Iter 2350: Fraction of documents with label changes: 0.298 %\n",
      "\n",
      "Iter 2400: Fraction of documents with label changes: 0.446 %\n",
      "\n",
      "Iter 2450: Fraction of documents with label changes: 0.446 %\n",
      "\n",
      "Iter 2500: Fraction of documents with label changes: 0.521 %\n",
      "\n",
      "Iter 2550: Fraction of documents with label changes: 0.818 %\n",
      "\n",
      "Iter 2600: Fraction of documents with label changes: 0.521 %\n",
      "\n",
      "Iter 2650: Fraction of documents with label changes: 0.372 %\n",
      "\n",
      "Iter 2700: Fraction of documents with label changes: 0.67 %\n",
      "\n",
      "Iter 2750: Fraction of documents with label changes: 0.298 %\n",
      "\n",
      "Iter 2800: Fraction of documents with label changes: 0.595 %\n",
      "\n",
      "Iter 2850: Fraction of documents with label changes: 0.372 %\n",
      "\n",
      "Iter 2900: Fraction of documents with label changes: 0.149 %\n",
      "\n",
      "Iter 2950: Fraction of documents with label changes: 0.223 %\n",
      "\n",
      "Iter 3000: Fraction of documents with label changes: 0.372 %\n",
      "\n",
      "Iter 3050: Fraction of documents with label changes: 0.223 %\n",
      "\n",
      "Iter 3100: Fraction of documents with label changes: 0.446 %\n",
      "\n",
      "Iter 3150: Fraction of documents with label changes: 0.298 %\n",
      "\n",
      "Iter 3200: Fraction of documents with label changes: 0.149 %\n",
      "\n",
      "Iter 3250: Fraction of documents with label changes: 0.223 %\n",
      "\n",
      "Iter 3300: Fraction of documents with label changes: 0.149 %\n",
      "\n",
      "Iter 3350: Fraction of documents with label changes: 0.372 %\n",
      "\n",
      "Iter 3400: Fraction of documents with label changes: 0.372 %\n",
      "\n",
      "Iter 3450: Fraction of documents with label changes: 0.223 %\n",
      "\n",
      "Iter 3500: Fraction of documents with label changes: 0.446 %\n",
      "\n",
      "Iter 3550: Fraction of documents with label changes: 0.298 %\n",
      "\n",
      "Iter 3600: Fraction of documents with label changes: 0.372 %\n",
      "\n",
      "Iter 3650: Fraction of documents with label changes: 0.149 %\n",
      "\n",
      "Iter 3700: Fraction of documents with label changes: 0.446 %\n",
      "\n",
      "Iter 3750: Fraction of documents with label changes: 0.223 %\n",
      "\n",
      "Iter 3800: Fraction of documents with label changes: 0.223 %\n",
      "\n",
      "Iter 3850: Fraction of documents with label changes: 0.298 %\n",
      "\n",
      "Iter 3900: Fraction of documents with label changes: 0.149 %\n",
      "\n",
      "Iter 3950: Fraction of documents with label changes: 0.298 %\n",
      "\n",
      "Iter 4000: Fraction of documents with label changes: 0.223 %\n",
      "\n",
      "Iter 4050: Fraction of documents with label changes: 0.149 %\n",
      "\n",
      "Iter 4100: Fraction of documents with label changes: 0.223 %\n",
      "\n",
      "Iter 4150: Fraction of documents with label changes: 0.372 %\n",
      "\n",
      "Iter 4200: Fraction of documents with label changes: 0.149 %\n",
      "\n",
      "Iter 4250: Fraction of documents with label changes: 0.074 %\n",
      "\n",
      "Fraction: 0.074 % < tol: 0.1 %\n",
      "Reached tolerance threshold. Stopping training.\n",
      "Final model saved to: ./results/news_manual/cnn/phase3/final.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Self-training time: 287.00s\n",
      "\n",
      "### Generating outputs ###\n",
      "Classification results are written in ./news_manual/out.txt\n",
      "1344\n"
     ]
    }
   ],
   "source": [
    "# Classification: WeSTClass\n",
    "!cd $cp5_home/ && $cp5_ipy frame_classification/url2west_append.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5151\n",
      "445\n",
      "1350\n",
      "2949\n",
      "1315\n",
      "593\n",
      "defaultdict(<class 'int'>, {'benefits/covid': 197, 'controversies/china/border': 56, 'leadership/khan': 108, 'benefits/development/maritime': 18, 'benefits/connections/afghanistan': 37, 'controversies/china/uighur': 27, 'benefits/jobs': 22, 'controversies/pakistan/baloch': 39, 'opposition/propaganda': 4, 'benefits/development/energy': 11, 'controversies/china/funding': 5, 'controversies/pakistan/army': 3, 'opposition/kashmir': 16, 'controversies/china/debt': 12, 'controversies/pakistan/students': 3, 'controversies/pakistan/bajwa': 15, 'controversies/china/exploitation': 9, 'controversies/china/naval': 7, 'leadership/sharif': 2, 'benefits/development/roads': 2})\n"
     ]
    }
   ],
   "source": [
    "# Collect all the classification results into a single file, pass the output to Tarek's group.\n",
    "!cd $cp5_home/ && $cp5_py collect_append.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n",
      "['/home/qiuwenda/CP5/cleaned/news_results_append.json']\n"
     ]
    }
   ],
   "source": [
    "# Read in the classification results\n",
    "\n",
    "import calendar\n",
    "import numpy as np\n",
    "import datetime\n",
    "import pandas as pd\n",
    "\n",
    "all_dates = [i.strftime(\"%Y-%m-%d\") for i in pd.date_range(start=\"2020-03-30\",end=\"2020-08-31\").to_pydatetime().tolist()]\n",
    "\n",
    "# print(all_dates)\n",
    "# stamp = str(int(calendar.timegm(datetime.datetime.strptime(d, \"%Y-%m-%d\").timetuple()))) + '000'\n",
    "narratives = ['benefits/connections/afghanistan', 'benefits/covid', 'benefits/development/energy', 'benefits/development/maritime', 'benefits/development/roads', 'benefits/jobs', 'controversies/china/border', 'controversies/china/debt', 'controversies/china/exploitation', 'controversies/china/funding', 'controversies/china/naval', 'controversies/china/uighur', 'controversies/pakistan/army', 'controversies/pakistan/bajwa', 'controversies/pakistan/baloch', 'controversies/pakistan/students', 'leadership/bajwa', 'leadership/khan', 'leadership/sharif', 'opposition/kashmir', 'opposition/propaganda']\n",
    "# selected_nar = ['controversies/pakistan/students', 'leadership/sharif', 'leadership/bajwa', 'controversies/china/uighur', 'controversies/china/border', 'benefits/development/roads', 'controversies/pakistan/baloch', 'benefits/jobs', 'opposition/propaganda', 'benefits/development/energy', 'controversies/pakistan/bajwa']\n",
    "selected_nar = narratives\n",
    "print(len(narratives))\n",
    "\n",
    "all_news_results = []\n",
    "import os\n",
    "for root, dirs, files in os.walk(cp5_home, topdown=False):\n",
    "    for name in sorted(list(files), key=lambda x: 'z' if x.startswith('news') else x):\n",
    "        if name.endswith('news_results_append.json'):\n",
    "            all_news_results.append(os.path.join(root, name))\n",
    "print(all_news_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "# gt_path = 'twitter_time_series_to_6_29.json'\n",
    "\n",
    "# with open(gt_path, 'r') as f:\n",
    "#     d = json.loads(f.read())\n",
    "# dd = {k: pd.read_json(v, orient='columns') for k, v in d.items()}\n",
    "# def get_gt_total(nar):\n",
    "#     if nar == 'other':\n",
    "#         tmp = [sum([dd[nar]['EventCount'][i] for nar in narratives if nar not in selected_nar]) for i in all_dates]\n",
    "#     else:\n",
    "#         tmp = [dd[nar]['EventCount'][i] for i in all_dates]\n",
    "#     return sum(tmp)\n",
    "# def get_gt_series(nar, norm='max'):\n",
    "#     if nar == 'other':\n",
    "#         tmp = [sum([dd[nar]['EventCount'][i] for nar in narratives if nar not in selected_nar]) for i in all_dates]\n",
    "#     else:\n",
    "#         tmp = [dd[nar]['EventCount'][i] for i in all_dates]\n",
    "#     if norm == 'max':\n",
    "#         x = max(*tmp)\n",
    "#     elif norm == 'sum':\n",
    "#         x = sum(tmp)\n",
    "#     else:\n",
    "#         x = 1\n",
    "#     x = max(x, 1e-5)\n",
    "#     return [i / x for i in tmp]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# import json\n",
    "# import pandas as pd\n",
    "# west_path = 'news_west_300_time_series_to_6_29.json'\n",
    "\n",
    "# with open(west_path, 'r') as f:\n",
    "#     w = json.loads(f.read())\n",
    "# ww = {k: pd.read_json('{\"EventCount\":' + v + '}', orient='columns') for k, v in w.items()}\n",
    "# def get_west_total(nar):\n",
    "#     if nar == 'other':\n",
    "#         return [0 for i in all_dates]\n",
    "#     else:\n",
    "#         tmp = [ww[nar]['EventCount'][i] for i in all_dates]\n",
    "#     return sum(tmp)\n",
    "# def get_west_series(nar, norm='max'):\n",
    "#     if nar == 'other':\n",
    "#         return [0 for i in all_dates]\n",
    "#     else:\n",
    "#         tmp = [ww[nar]['EventCount'][i] for i in all_dates]\n",
    "#     if norm == 'max':\n",
    "#         x = max(*tmp)\n",
    "#     elif norm == 'sum':\n",
    "#         x = sum(tmp)\n",
    "#     else:\n",
    "#         x = 1\n",
    "#     x = max(x, 1e-5)\n",
    "#     return [i / x for i in tmp]\n",
    "\n",
    "# west_series = dict()\n",
    "# for n in selected_nar:\n",
    "#     west_series[n] = {i:ww[n]['EventCount'][i] for i in all_dates}\n",
    "# west_series['other'] = {i:0 for i in all_dates}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/qiuwenda/CP5/cleaned/news_results_append.json\n"
     ]
    }
   ],
   "source": [
    "# Compute time series (daily volume) for each method and frame\n",
    "from collections import defaultdict\n",
    "narrative_list = narratives\n",
    "string_match_series = {i:defaultdict(float) for i in narratives}\n",
    "leidos_bert_series = {i:defaultdict(float) for i in narratives}\n",
    "westclass_series = {i:defaultdict(float) for i in narratives}\n",
    "lotclass_series = {i:defaultdict(float) for i in narratives}\n",
    "tuned_bert_series = {i:defaultdict(float) for i in narratives}\n",
    "for fn in all_news_results:\n",
    "    print(fn)\n",
    "    with open(f'{fn}') as fin:\n",
    "        for line in fin:\n",
    "            js = json.loads(line)\n",
    "#             if js['relevance_prediction']:\n",
    "            if js['leidos_bert_prediction'] and js['date']:\n",
    "                n = js['leidos_bert_prediction'][0]\n",
    "#                 if n not in selected_nar:\n",
    "#                     n = 'other'\n",
    "                leidos_bert_series[n][js['date']] += 1\n",
    "            if js['string_match_prediction'] and js['date']:\n",
    "                n = js['string_match_prediction'][0]\n",
    "#                 if n not in selected_nar:\n",
    "#                     n = 'other'\n",
    "                string_match_series[n][js['date']] += 1\n",
    "            if js['westclass_prediction'] and js['date']:\n",
    "                n = js['westclass_prediction'][0]\n",
    "#                 if n not in selected_nar:\n",
    "#                     n = 'other'\n",
    "                westclass_series[n][js['date']] += 1\n",
    "#             if js['lotclass_prediction'] and js['date']:\n",
    "#                 n = js['lotclass_prediction'][0]\n",
    "# #                 if n not in selected_nar:\n",
    "# #                     n = 'other'\n",
    "#                 lotclass_series[n][js['date']] += 1\n",
    "#             if js['tuned_bert_prediction'] and js['date']:\n",
    "#                 n = js['tuned_bert_prediction'][0]\n",
    "# #                 if n not in selected_nar:\n",
    "# #                     n = 'other'\n",
    "#                 tuned_bert_series[n][js['date']] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['benefits/connections/afghanistan', 'benefits/covid', 'benefits/development/energy', 'benefits/development/maritime', 'benefits/development/roads', 'benefits/jobs', 'controversies/china/border', 'controversies/china/debt', 'controversies/china/exploitation', 'controversies/china/funding', 'controversies/china/naval', 'controversies/china/uighur', 'controversies/pakistan/army', 'controversies/pakistan/bajwa', 'controversies/pakistan/baloch', 'controversies/pakistan/students', 'leadership/bajwa', 'leadership/khan', 'leadership/sharif', 'opposition/kashmir', 'opposition/propaganda']\n",
      "['2020-03-30', '2020-03-31', '2020-04-01', '2020-04-02', '2020-04-03', '2020-04-04', '2020-04-05', '2020-04-06', '2020-04-07', '2020-04-08', '2020-04-09', '2020-04-10', '2020-04-11', '2020-04-12', '2020-04-13', '2020-04-14', '2020-04-15', '2020-04-16', '2020-04-17', '2020-04-18', '2020-04-19', '2020-04-20', '2020-04-21', '2020-04-22', '2020-04-23', '2020-04-24', '2020-04-25', '2020-04-26', '2020-04-27', '2020-04-28', '2020-04-29', '2020-04-30', '2020-05-01', '2020-05-02', '2020-05-03', '2020-05-04', '2020-05-05', '2020-05-06', '2020-05-07', '2020-05-08', '2020-05-09', '2020-05-10', '2020-05-11', '2020-05-12', '2020-05-13', '2020-05-14', '2020-05-15', '2020-05-16', '2020-05-17', '2020-05-18', '2020-05-19', '2020-05-20', '2020-05-21', '2020-05-22', '2020-05-23', '2020-05-24', '2020-05-25', '2020-05-26', '2020-05-27', '2020-05-28', '2020-05-29', '2020-05-30', '2020-05-31', '2020-06-01', '2020-06-02', '2020-06-03', '2020-06-04', '2020-06-05', '2020-06-06', '2020-06-07', '2020-06-08', '2020-06-09', '2020-06-10', '2020-06-11', '2020-06-12', '2020-06-13', '2020-06-14', '2020-06-15', '2020-06-16', '2020-06-17', '2020-06-18', '2020-06-19', '2020-06-20', '2020-06-21', '2020-06-22', '2020-06-23', '2020-06-24', '2020-06-25', '2020-06-26', '2020-06-27', '2020-06-28', '2020-06-29', '2020-06-30', '2020-07-01', '2020-07-02', '2020-07-03', '2020-07-04', '2020-07-05', '2020-07-06', '2020-07-07', '2020-07-08', '2020-07-09', '2020-07-10', '2020-07-11', '2020-07-12', '2020-07-13', '2020-07-14', '2020-07-15', '2020-07-16', '2020-07-17', '2020-07-18', '2020-07-19', '2020-07-20', '2020-07-21', '2020-07-22', '2020-07-23', '2020-07-24', '2020-07-25', '2020-07-26', '2020-07-27', '2020-07-28', '2020-07-29', '2020-07-30', '2020-07-31', '2020-08-01', '2020-08-02', '2020-08-03', '2020-08-04', '2020-08-05', '2020-08-06', '2020-08-07', '2020-08-08', '2020-08-09', '2020-08-10', '2020-08-11', '2020-08-12', '2020-08-13', '2020-08-14', '2020-08-15', '2020-08-16', '2020-08-17', '2020-08-18', '2020-08-19', '2020-08-20', '2020-08-21', '2020-08-22', '2020-08-23', '2020-08-24', '2020-08-25', '2020-08-26', '2020-08-27', '2020-08-28', '2020-08-29', '2020-08-30', '2020-08-31']\n"
     ]
    }
   ],
   "source": [
    "narrative_list = narratives\n",
    "print(narrative_list)\n",
    "print(all_dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dump all the time series\n",
    "def dump_series(news_event, fn):\n",
    "    news_time = dict()\n",
    "    for n in narrative_list:\n",
    "        tmp = dict()\n",
    "        for d in all_dates:\n",
    "            stamp = str(int(calendar.timegm(datetime.datetime.strptime(d, \"%Y-%m-%d\").timetuple()))) + '000'\n",
    "            tmp[stamp] = news_event[n][d]\n",
    "        news_time[n] = tmp\n",
    "#     json.dump({i:json.dumps({'EventCount': news_time[i]}) for i in news_time}, open(fn, 'w'))\n",
    "    json.dump({i:json.dumps(news_time[i]) for i in news_time}, open(fn, 'w'))\n",
    "dump_series(leidos_bert_series, f'news_leidos_bert_time_series_to_{series_end_date}.json')\n",
    "dump_series(string_match_series, f'news_string_match_time_series_to_{series_end_date}.json')\n",
    "dump_series(westclass_series, f'news_westclass_time_series_to_{series_end_date}.json')\n",
    "# dump_series(lotclass_series, f'news_lotclass_time_series_to_{series_end_date}.json')\n",
    "# dump_series(tuned_bert_series, f'news_tuned_bert_time_series_to_{series_end_date}.json')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "series_results = {'leidos_bert': leidos_bert_series, 'string_match': string_match_series, 'westclass': westclass_series} #, 'lotclass': lotclass_series, 'tuned_bert': tuned_bert_series}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'tuned_bert'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-1896631e5a37>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0mtime_series\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnar\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mseries\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mwhich\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnar\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtime_series\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mpfpm_series\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchoose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseries_results\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0mdump_series\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpfpm_series\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf'news_pfpm_5_hybrid_time_series_to_{series_end_date}.json'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-26-1896631e5a37>\u001b[0m in \u001b[0;36mchoose\u001b[0;34m(series)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mnar\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnarratives\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mwhich\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnar2optimal_choice\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnar\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mseries\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mwhich\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnar\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m             \u001b[0mtime_series\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnar\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mseries\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mwhich\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnar\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtime_series\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'tuned_bert'"
     ]
    }
   ],
   "source": [
    "# Hybrid time series: per-frame-per-method, choose the best classification for each frame, in terms of the correlation with ground truth tweet time series (training period).\n",
    "\n",
    "# nar2optimal_choice = {\"benefits/connections/afghanistan\": \"tuned_bert\", \"benefits/covid\": \"westclass\", \"benefits/development/energy\": \"leidos_bert\", \"benefits/development/maritime\": \"leidos_bert\", \"benefits/development/roads\": \"lotclass\", \"benefits/jobs\": \"lotclass\", \"controversies/china/border\": \"string_match\", \"controversies/china/debt\": \"westclass\", \"controversies/china/exploitation\": \"tuned_bert\", \"controversies/china/funding\": \"leidos_bert\", \"controversies/china/naval\": \"tuned_bert\", \"controversies/china/uighur\": \"westclass\", \"controversies/pakistan/army\": \"tuned_bert\", \"controversies/pakistan/bajwa\": \"tuned_bert\", \"controversies/pakistan/baloch\": \"westclass\", \"controversies/pakistan/students\": \"lotclass\", \"leadership/bajwa\": \"tuned_bert\", \"leadership/khan\": \"leidos_bert\", \"leadership/sharif\": \"tuned_bert\", \"opposition/kashmir\": \"string_match\", \"opposition/propaganda\": \"string_match\"}\n",
    "# nar2optimal_choice = {\"benefits/connections/afghanistan\": \"tuned_bert\", \"benefits/covid\": \"westclass\", \"benefits/development/energy\": \"leidos_bert\", \"benefits/development/maritime\": \"leidos_bert\", \"benefits/development/roads\": \"lotclass\", \"benefits/jobs\": \"lotclass\", \"controversies/china/border\": \"string_match\", \"controversies/china/debt\": \"westclass\", \"controversies/china/exploitation\": \"tuned_bert\", \"controversies/china/funding\": \"leidos_bert\", \"controversies/china/naval\": \"tuned_bert\", \"controversies/china/uighur\": \"westclass\", \"controversies/pakistan/army\": \"tuned_bert\", \"controversies/pakistan/bajwa\": \"tuned_bert\", \"controversies/pakistan/baloch\": \"westclass\", \"controversies/pakistan/students\": \"lotclass\", \"leadership/bajwa\": \"tuned_bert\", \"leadership/khan\": \"leidos_bert\", \"leadership/sharif\": \"tuned_bert\", \"opposition/kashmir\": \"string_match\", \"opposition/propaganda\": \"string_match\"}\n",
    "# nar2optimal_choice = {\"benefits/connections/afghanistan\": \"tuned_bert\", \"benefits/covid\": \"westclass\", \"benefits/development/energy\": \"leidos_bert\", \"benefits/development/maritime\": \"leidos_bert\", \"benefits/development/roads\": \"lotclass\", \"benefits/jobs\": \"lotclass\", \"controversies/china/border\": \"string_match\", \"controversies/china/debt\": \"westclass\", \"controversies/china/exploitation\": \"tuned_bert\", \"controversies/china/funding\": \"leidos_bert\", \"controversies/china/naval\": \"tuned_bert\", \"controversies/china/uighur\": \"westclass\", \"controversies/pakistan/army\": \"tuned_bert\", \"controversies/pakistan/bajwa\": \"tuned_bert\", \"controversies/pakistan/baloch\": \"westclass\", \"controversies/pakistan/students\": \"lotclass\", \"leadership/bajwa\": \"tuned_bert\", \"leadership/khan\": \"leidos_bert\", \"leadership/sharif\": \"tuned_bert\", \"opposition/kashmir\": \"string_match\", \"opposition/propaganda\": \"string_match\"}\n",
    "# nar2optimal_choice = {\"benefits/connections/afghanistan\": \"tuned_bert\", \"benefits/covid\": \"westclass\", \"benefits/development/energy\": \"leidos_bert\", \"benefits/development/maritime\": \"leidos_bert\", \"benefits/development/roads\": \"lotclass\", \"benefits/jobs\": \"lotclass\", \"controversies/china/border\": \"string_match\", \"controversies/china/debt\": \"westclass\", \"controversies/china/exploitation\": \"tuned_bert\", \"controversies/china/funding\": \"leidos_bert\", \"controversies/china/naval\": \"tuned_bert\", \"controversies/china/uighur\": \"westclass\", \"controversies/pakistan/army\": \"tuned_bert\", \"controversies/pakistan/bajwa\": \"tuned_bert\", \"controversies/pakistan/baloch\": \"westclass\", \"controversies/pakistan/students\": \"lotclass\", \"leadership/bajwa\": \"tuned_bert\", \"leadership/khan\": \"leidos_bert\", \"leadership/sharif\": \"tuned_bert\", \"opposition/kashmir\": \"string_match\", \"opposition/propaganda\": \"string_match\"}\n",
    "# nar2optimal_choice = {\"benefits/connections/afghanistan\": \"tuned_bert\", \"benefits/covid\": \"westclass\", \"benefits/development/energy\": \"leidos_bert\", \"benefits/development/maritime\": \"leidos_bert\", \"benefits/development/roads\": \"lotclass\", \"benefits/jobs\": \"lotclass\", \"controversies/china/border\": \"string_match\", \"controversies/china/debt\": \"westclass\", \"controversies/china/exploitation\": \"tuned_bert\", \"controversies/china/funding\": \"leidos_bert\", \"controversies/china/naval\": \"tuned_bert\", \"controversies/china/uighur\": \"westclass\", \"controversies/pakistan/army\": \"tuned_bert\", \"controversies/pakistan/bajwa\": \"tuned_bert\", \"controversies/pakistan/baloch\": \"westclass\", \"controversies/pakistan/students\": \"lotclass\", \"leadership/bajwa\": \"tuned_bert\", \"leadership/khan\": \"leidos_bert\", \"leadership/sharif\": \"tuned_bert\", \"opposition/kashmir\": \"string_match\", \"opposition/propaganda\": \"string_match\"}\n",
    "# def choose(series):\n",
    "#     time_series = {i:defaultdict(float) for i in narratives}\n",
    "#     for nar in narratives:\n",
    "#         which = nar2optimal_choice[nar]\n",
    "#         for d in series[which][nar]:\n",
    "#             time_series[nar][d] += series[which][nar][d]\n",
    "#     return time_series\n",
    "# pfpm_series = choose(series_results)\n",
    "# dump_series(pfpm_series, f'news_pfpm_5_hybrid_time_series_to_{series_end_date}.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hybrid time series: weighted sum, the optimal weighting is decided by the correlation between tweet series (training) abd news series\n",
    "\n",
    "# optimal_weighting = {\"benefits/connections/afghanistan\": {\"westclass\": 4, \"string_match\": 5, \"leidos_bert\": 7}, \"benefits/covid\": {\"westclass\": 10, \"string_match\": 0, \"leidos_bert\": 0}, \"benefits/development/energy\": {\"westclass\": 0, \"string_match\": 0, \"leidos_bert\": 10}, \"benefits/development/maritime\": {\"westclass\": 0, \"string_match\": 0, \"leidos_bert\": 10}, \"benefits/development/roads\": {\"westclass\": 0, \"string_match\": 0, \"leidos_bert\": 10}, \"benefits/jobs\": {\"westclass\": 9, \"string_match\": 0, \"leidos_bert\": 5}, \"controversies/china/border\": {\"westclass\": 0, \"string_match\": 8, \"leidos_bert\": 5}, \"controversies/china/debt\": {\"westclass\": 0, \"string_match\": 10, \"leidos_bert\": 5}, \"controversies/china/exploitation\": {\"westclass\": 0, \"string_match\": 0, \"leidos_bert\": 10}, \"controversies/china/funding\": {\"westclass\": 0, \"string_match\": 0, \"leidos_bert\": 10}, \"controversies/china/naval\": {\"westclass\": 0, \"string_match\": 9, \"leidos_bert\": 3}, \"controversies/china/uighur\": {\"westclass\": 10, \"string_match\": 0, \"leidos_bert\": 0}, \"controversies/pakistan/army\": {\"westclass\": 10, \"string_match\": 5, \"leidos_bert\": 3}, \"controversies/pakistan/bajwa\": {\"westclass\": 2, \"string_match\": 0, \"leidos_bert\": 9}, \"controversies/pakistan/baloch\": {\"westclass\": 10, \"string_match\": 0, \"leidos_bert\": 3}, \"controversies/pakistan/students\": {\"westclass\": 0, \"string_match\": 0, \"leidos_bert\": 10}, \"leadership/bajwa\": {\"westclass\": 10, \"string_match\": 3, \"leidos_bert\": 0}, \"leadership/khan\": {\"westclass\": 10, \"string_match\": 0, \"leidos_bert\": 10}, \"leadership/sharif\": {\"westclass\": 0, \"string_match\": 0, \"leidos_bert\": 10}, \"opposition/kashmir\": {\"westclass\": 0, \"string_match\": 7, \"leidos_bert\": 5}, \"opposition/propaganda\": {\"westclass\": 10, \"string_match\": 0, \"leidos_bert\": 1}}\n",
    "# optimal_weighting = {\"benefits/connections/afghanistan\": {\"westclass\": 0, \"string_match\": 0, \"leidos_bert\": 1, \"lotclass\": 0, \"tuned_bert\": 10}, \"benefits/covid\": {\"westclass\": 1, \"string_match\": 0, \"leidos_bert\": 0, \"lotclass\": 0, \"tuned_bert\": 1}, \"benefits/development/energy\": {\"westclass\": 0, \"string_match\": 0, \"leidos_bert\": 1, \"lotclass\": 0, \"tuned_bert\": 0}, \"benefits/development/maritime\": {\"westclass\": 0, \"string_match\": 0, \"leidos_bert\": 1, \"lotclass\": 0, \"tuned_bert\": 0}, \"benefits/development/roads\": {\"westclass\": 0, \"string_match\": 0, \"leidos_bert\": 0, \"lotclass\": 1, \"tuned_bert\": 0}, \"benefits/jobs\": {\"westclass\": 1, \"string_match\": 0, \"leidos_bert\": 1, \"lotclass\": 10, \"tuned_bert\": 0}, \"controversies/china/border\": {\"westclass\": 0, \"string_match\": 1, \"leidos_bert\": 1, \"lotclass\": 5, \"tuned_bert\": 0}, \"controversies/china/debt\": {\"westclass\": 3, \"string_match\": 0, \"leidos_bert\": 6, \"lotclass\": 10, \"tuned_bert\": 0}, \"controversies/china/exploitation\": {\"westclass\": 0, \"string_match\": 0, \"leidos_bert\": 0, \"lotclass\": 7, \"tuned_bert\": 10}, \"controversies/china/funding\": {\"westclass\": 0, \"string_match\": 0, \"leidos_bert\": 6, \"lotclass\": 0, \"tuned_bert\": 5}, \"controversies/china/naval\": {\"westclass\": 0, \"string_match\": 0, \"leidos_bert\": 8, \"lotclass\": 2, \"tuned_bert\": 5}, \"controversies/china/uighur\": {\"westclass\": 10, \"string_match\": 0, \"leidos_bert\": 0, \"lotclass\": 3, \"tuned_bert\": 1}, \"controversies/pakistan/army\": {\"westclass\": 9, \"string_match\": 1, \"leidos_bert\": 8, \"lotclass\": 9, \"tuned_bert\": 3}, \"controversies/pakistan/bajwa\": {\"westclass\": 0, \"string_match\": 0, \"leidos_bert\": 0, \"lotclass\": 9, \"tuned_bert\": 7}, \"controversies/pakistan/baloch\": {\"westclass\": 10, \"string_match\": 0, \"leidos_bert\": 3, \"lotclass\": 2, \"tuned_bert\": 0}, \"controversies/pakistan/students\": {\"westclass\": 0, \"string_match\": 1, \"leidos_bert\": 0, \"lotclass\": 10, \"tuned_bert\": 0}, \"leadership/bajwa\": {\"westclass\": 3, \"string_match\": 8, \"leidos_bert\": 0, \"lotclass\": 0, \"tuned_bert\": 9}, \"leadership/khan\": {\"westclass\": 9, \"string_match\": 0, \"leidos_bert\": 7, \"lotclass\": 9, \"tuned_bert\": 2}, \"leadership/sharif\": {\"westclass\": 0, \"string_match\": 0, \"leidos_bert\": 0, \"lotclass\": 0, \"tuned_bert\": 1}, \"opposition/kashmir\": {\"westclass\": 0, \"string_match\": 1, \"leidos_bert\": 0, \"lotclass\": 0, \"tuned_bert\": 0}, \"opposition/propaganda\": {\"westclass\": 10, \"string_match\": 10, \"leidos_bert\": 1, \"lotclass\": 1, \"tuned_bert\": 0}}\n",
    "# optimal_weighting = {\"benefits/connections/afghanistan\": {\"westclass\": 0, \"string_match\": 0, \"leidos_bert\": 1, \"lotclass\": 0, \"tuned_bert\": 10}, \"benefits/covid\": {\"westclass\": 1, \"string_match\": 0, \"leidos_bert\": 0, \"lotclass\": 0, \"tuned_bert\": 1}, \"benefits/development/energy\": {\"westclass\": 0, \"string_match\": 0, \"leidos_bert\": 1, \"lotclass\": 0, \"tuned_bert\": 0}, \"benefits/development/maritime\": {\"westclass\": 0, \"string_match\": 0, \"leidos_bert\": 1, \"lotclass\": 0, \"tuned_bert\": 0}, \"benefits/development/roads\": {\"westclass\": 0, \"string_match\": 0, \"leidos_bert\": 0, \"lotclass\": 1, \"tuned_bert\": 0}, \"benefits/jobs\": {\"westclass\": 1, \"string_match\": 0, \"leidos_bert\": 1, \"lotclass\": 10, \"tuned_bert\": 0}, \"controversies/china/border\": {\"westclass\": 0, \"string_match\": 1, \"leidos_bert\": 1, \"lotclass\": 5, \"tuned_bert\": 0}, \"controversies/china/debt\": {\"westclass\": 3, \"string_match\": 0, \"leidos_bert\": 6, \"lotclass\": 10, \"tuned_bert\": 0}, \"controversies/china/exploitation\": {\"westclass\": 0, \"string_match\": 0, \"leidos_bert\": 0, \"lotclass\": 9, \"tuned_bert\": 10}, \"controversies/china/funding\": {\"westclass\": 0, \"string_match\": 0, \"leidos_bert\": 7, \"lotclass\": 0, \"tuned_bert\": 6}, \"controversies/china/naval\": {\"westclass\": 0, \"string_match\": 0, \"leidos_bert\": 8, \"lotclass\": 2, \"tuned_bert\": 5}, \"controversies/china/uighur\": {\"westclass\": 10, \"string_match\": 0, \"leidos_bert\": 0, \"lotclass\": 2, \"tuned_bert\": 1}, \"controversies/pakistan/army\": {\"westclass\": 9, \"string_match\": 1, \"leidos_bert\": 8, \"lotclass\": 9, \"tuned_bert\": 3}, \"controversies/pakistan/bajwa\": {\"westclass\": 0, \"string_match\": 0, \"leidos_bert\": 0, \"lotclass\": 9, \"tuned_bert\": 7}, \"controversies/pakistan/baloch\": {\"westclass\": 10, \"string_match\": 0, \"leidos_bert\": 3, \"lotclass\": 2, \"tuned_bert\": 0}, \"controversies/pakistan/students\": {\"westclass\": 0, \"string_match\": 1, \"leidos_bert\": 0, \"lotclass\": 10, \"tuned_bert\": 0}, \"leadership/bajwa\": {\"westclass\": 3, \"string_match\": 4, \"leidos_bert\": 0, \"lotclass\": 0, \"tuned_bert\": 8}, \"leadership/khan\": {\"westclass\": 9, \"string_match\": 0, \"leidos_bert\": 7, \"lotclass\": 9, \"tuned_bert\": 2}, \"leadership/sharif\": {\"westclass\": 0, \"string_match\": 0, \"leidos_bert\": 0, \"lotclass\": 0, \"tuned_bert\": 1}, \"opposition/kashmir\": {\"westclass\": 0, \"string_match\": 1, \"leidos_bert\": 0, \"lotclass\": 0, \"tuned_bert\": 0}, \"opposition/propaganda\": {\"westclass\": 7, \"string_match\": 10, \"leidos_bert\": 1, \"lotclass\": 2, \"tuned_bert\": 0}}\n",
    "# optimal_weighting = {\"benefits/connections/afghanistan\": {\"westclass\": 0, \"string_match\": 0, \"leidos_bert\": 1, \"lotclass\": 0, \"tuned_bert\": 10}, \"benefits/covid\": {\"westclass\": 1, \"string_match\": 0, \"leidos_bert\": 0, \"lotclass\": 0, \"tuned_bert\": 1}, \"benefits/development/energy\": {\"westclass\": 0, \"string_match\": 0, \"leidos_bert\": 1, \"lotclass\": 0, \"tuned_bert\": 0}, \"benefits/development/maritime\": {\"westclass\": 0, \"string_match\": 0, \"leidos_bert\": 1, \"lotclass\": 0, \"tuned_bert\": 0}, \"benefits/development/roads\": {\"westclass\": 0, \"string_match\": 0, \"leidos_bert\": 0, \"lotclass\": 1, \"tuned_bert\": 0}, \"benefits/jobs\": {\"westclass\": 1, \"string_match\": 0, \"leidos_bert\": 1, \"lotclass\": 10, \"tuned_bert\": 0}, \"controversies/china/border\": {\"westclass\": 0, \"string_match\": 1, \"leidos_bert\": 1, \"lotclass\": 5, \"tuned_bert\": 0}, \"controversies/china/debt\": {\"westclass\": 3, \"string_match\": 0, \"leidos_bert\": 6, \"lotclass\": 10, \"tuned_bert\": 0}, \"controversies/china/exploitation\": {\"westclass\": 0, \"string_match\": 0, \"leidos_bert\": 0, \"lotclass\": 7, \"tuned_bert\": 8}, \"controversies/china/funding\": {\"westclass\": 0, \"string_match\": 0, \"leidos_bert\": 7, \"lotclass\": 0, \"tuned_bert\": 6}, \"controversies/china/naval\": {\"westclass\": 0, \"string_match\": 0, \"leidos_bert\": 8, \"lotclass\": 2, \"tuned_bert\": 5}, \"controversies/china/uighur\": {\"westclass\": 10, \"string_match\": 0, \"leidos_bert\": 0, \"lotclass\": 2, \"tuned_bert\": 1}, \"controversies/pakistan/army\": {\"westclass\": 9, \"string_match\": 1, \"leidos_bert\": 8, \"lotclass\": 9, \"tuned_bert\": 3}, \"controversies/pakistan/bajwa\": {\"westclass\": 0, \"string_match\": 0, \"leidos_bert\": 0, \"lotclass\": 9, \"tuned_bert\": 7}, \"controversies/pakistan/baloch\": {\"westclass\": 10, \"string_match\": 0, \"leidos_bert\": 3, \"lotclass\": 8, \"tuned_bert\": 0}, \"controversies/pakistan/students\": {\"westclass\": 0, \"string_match\": 1, \"leidos_bert\": 0, \"lotclass\": 10, \"tuned_bert\": 0}, \"leadership/bajwa\": {\"westclass\": 3, \"string_match\": 4, \"leidos_bert\": 0, \"lotclass\": 0, \"tuned_bert\": 8}, \"leadership/khan\": {\"westclass\": 10, \"string_match\": 0, \"leidos_bert\": 1, \"lotclass\": 8, \"tuned_bert\": 0}, \"leadership/sharif\": {\"westclass\": 0, \"string_match\": 0, \"leidos_bert\": 0, \"lotclass\": 0, \"tuned_bert\": 1}, \"opposition/kashmir\": {\"westclass\": 0, \"string_match\": 1, \"leidos_bert\": 0, \"lotclass\": 0, \"tuned_bert\": 0}, \"opposition/propaganda\": {\"westclass\": 0, \"string_match\": 10, \"leidos_bert\": 0, \"lotclass\": 1, \"tuned_bert\": 0}}\n",
    "# optimal_weighting = {\"benefits/connections/afghanistan\": {\"westclass\": 0, \"string_match\": 0, \"leidos_bert\": 1, \"lotclass\": 0, \"tuned_bert\": 10}, \"benefits/covid\": {\"westclass\": 1, \"string_match\": 0, \"leidos_bert\": 0, \"lotclass\": 0, \"tuned_bert\": 1}, \"benefits/development/energy\": {\"westclass\": 0, \"string_match\": 0, \"leidos_bert\": 1, \"lotclass\": 0, \"tuned_bert\": 0}, \"benefits/development/maritime\": {\"westclass\": 0, \"string_match\": 0, \"leidos_bert\": 1, \"lotclass\": 0, \"tuned_bert\": 0}, \"benefits/development/roads\": {\"westclass\": 0, \"string_match\": 0, \"leidos_bert\": 0, \"lotclass\": 1, \"tuned_bert\": 0}, \"benefits/jobs\": {\"westclass\": 1, \"string_match\": 0, \"leidos_bert\": 1, \"lotclass\": 10, \"tuned_bert\": 0}, \"controversies/china/border\": {\"westclass\": 0, \"string_match\": 1, \"leidos_bert\": 1, \"lotclass\": 5, \"tuned_bert\": 0}, \"controversies/china/debt\": {\"westclass\": 3, \"string_match\": 0, \"leidos_bert\": 6, \"lotclass\": 10, \"tuned_bert\": 0}, \"controversies/china/exploitation\": {\"westclass\": 0, \"string_match\": 0, \"leidos_bert\": 0, \"lotclass\": 7, \"tuned_bert\": 8}, \"controversies/china/funding\": {\"westclass\": 0, \"string_match\": 0, \"leidos_bert\": 7, \"lotclass\": 0, \"tuned_bert\": 6}, \"controversies/china/naval\": {\"westclass\": 0, \"string_match\": 0, \"leidos_bert\": 8, \"lotclass\": 2, \"tuned_bert\": 5}, \"controversies/china/uighur\": {\"westclass\": 10, \"string_match\": 0, \"leidos_bert\": 0, \"lotclass\": 2, \"tuned_bert\": 1}, \"controversies/pakistan/army\": {\"westclass\": 9, \"string_match\": 1, \"leidos_bert\": 8, \"lotclass\": 10, \"tuned_bert\": 3}, \"controversies/pakistan/bajwa\": {\"westclass\": 0, \"string_match\": 0, \"leidos_bert\": 0, \"lotclass\": 9, \"tuned_bert\": 7}, \"controversies/pakistan/baloch\": {\"westclass\": 10, \"string_match\": 0, \"leidos_bert\": 3, \"lotclass\": 8, \"tuned_bert\": 0}, \"controversies/pakistan/students\": {\"westclass\": 0, \"string_match\": 1, \"leidos_bert\": 0, \"lotclass\": 10, \"tuned_bert\": 0}, \"leadership/bajwa\": {\"westclass\": 3, \"string_match\": 3, \"leidos_bert\": 0, \"lotclass\": 0, \"tuned_bert\": 10}, \"leadership/khan\": {\"westclass\": 10, \"string_match\": 0, \"leidos_bert\": 1, \"lotclass\": 8, \"tuned_bert\": 0}, \"leadership/sharif\": {\"westclass\": 0, \"string_match\": 0, \"leidos_bert\": 0, \"lotclass\": 0, \"tuned_bert\": 1}, \"opposition/kashmir\": {\"westclass\": 0, \"string_match\": 1, \"leidos_bert\": 0, \"lotclass\": 0, \"tuned_bert\": 0}, \"opposition/propaganda\": {\"westclass\": 0, \"string_match\": 10, \"leidos_bert\": 0, \"lotclass\": 1, \"tuned_bert\": 0}}\n",
    "# optimal_weighting = {\"benefits/connections/afghanistan\": {\"westclass\": 0, \"string_match\": 0, \"leidos_bert\": 1, \"lotclass\": 0, \"tuned_bert\": 10}, \"benefits/covid\": {\"westclass\": 9, \"string_match\": 0, \"leidos_bert\": 0, \"lotclass\": 0, \"tuned_bert\": 10}, \"benefits/development/energy\": {\"westclass\": 0, \"string_match\": 0, \"leidos_bert\": 1, \"lotclass\": 0, \"tuned_bert\": 0}, \"benefits/development/maritime\": {\"westclass\": 0, \"string_match\": 0, \"leidos_bert\": 1, \"lotclass\": 0, \"tuned_bert\": 0}, \"benefits/development/roads\": {\"westclass\": 0, \"string_match\": 0, \"leidos_bert\": 0, \"lotclass\": 1, \"tuned_bert\": 0}, \"benefits/jobs\": {\"westclass\": 1, \"string_match\": 0, \"leidos_bert\": 1, \"lotclass\": 10, \"tuned_bert\": 0}, \"controversies/china/border\": {\"westclass\": 0, \"string_match\": 1, \"leidos_bert\": 1, \"lotclass\": 5, \"tuned_bert\": 0}, \"controversies/china/debt\": {\"westclass\": 3, \"string_match\": 0, \"leidos_bert\": 6, \"lotclass\": 8, \"tuned_bert\": 0}, \"controversies/china/exploitation\": {\"westclass\": 0, \"string_match\": 0, \"leidos_bert\": 0, \"lotclass\": 9, \"tuned_bert\": 10}, \"controversies/china/funding\": {\"westclass\": 0, \"string_match\": 0, \"leidos_bert\": 7, \"lotclass\": 0, \"tuned_bert\": 6}, \"controversies/china/naval\": {\"westclass\": 0, \"string_match\": 0, \"leidos_bert\": 8, \"lotclass\": 2, \"tuned_bert\": 5}, \"controversies/china/uighur\": {\"westclass\": 10, \"string_match\": 0, \"leidos_bert\": 0, \"lotclass\": 2, \"tuned_bert\": 1}, \"controversies/pakistan/army\": {\"westclass\": 9, \"string_match\": 1, \"leidos_bert\": 8, \"lotclass\": 9, \"tuned_bert\": 3}, \"controversies/pakistan/bajwa\": {\"westclass\": 0, \"string_match\": 0, \"leidos_bert\": 0, \"lotclass\": 9, \"tuned_bert\": 7}, \"controversies/pakistan/baloch\": {\"westclass\": 3, \"string_match\": 0, \"leidos_bert\": 1, \"lotclass\": 4, \"tuned_bert\": 0}, \"controversies/pakistan/students\": {\"westclass\": 0, \"string_match\": 1, \"leidos_bert\": 0, \"lotclass\": 10, \"tuned_bert\": 0}, \"leadership/bajwa\": {\"westclass\": 1, \"string_match\": 3, \"leidos_bert\": 0, \"lotclass\": 0, \"tuned_bert\": 6}, \"leadership/khan\": {\"westclass\": 10, \"string_match\": 0, \"leidos_bert\": 1, \"lotclass\": 1, \"tuned_bert\": 0}, \"leadership/sharif\": {\"westclass\": 0, \"string_match\": 0, \"leidos_bert\": 0, \"lotclass\": 0, \"tuned_bert\": 1}, \"opposition/kashmir\": {\"westclass\": 0, \"string_match\": 1, \"leidos_bert\": 0, \"lotclass\": 0, \"tuned_bert\": 0}, \"opposition/propaganda\": {\"westclass\": 0, \"string_match\": 10, \"leidos_bert\": 0, \"lotclass\": 1, \"tuned_bert\": 0}}\n",
    "# def combine(series):\n",
    "#     time_series = {i:defaultdict(float) for i in narratives}\n",
    "#     for nar in narratives:\n",
    "#         for method in optimal_weighting[nar]:\n",
    "#             w = optimal_weighting[nar][method]\n",
    "#             for d in series[method][nar]:\n",
    "#                 time_series[nar][d] += series[method][nar][d] * w\n",
    "#         base = sum(optimal_weighting[nar].values())\n",
    "#         for d in time_series[nar]:\n",
    "#             time_series[nar][d] /= base\n",
    "#     return time_series\n",
    "# weighted_series = combine(series_results)\n",
    "# dump_series(weighted_series, f'news_weighted_5_hybrid_time_series_to_{series_end_date}.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib inline\n",
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "\n",
    "# def get_series(nar, s, norm='max'):\n",
    "#     tmp = [s[nar][i] for i in all_dates]\n",
    "#     if norm == 'max':\n",
    "#         x = max(*tmp)\n",
    "#     elif norm == 'sum':\n",
    "#         x = sum(tmp)\n",
    "#     else:\n",
    "#         x = 1\n",
    "#     x = max(x, 1e-5)\n",
    "#     return [i / x for i in tmp]\n",
    "\n",
    "# fig, _axes = plt.subplots(4, 3, figsize=(15, 12))\n",
    "# axes = []\n",
    "# for i in _axes:\n",
    "#     for ax in i:\n",
    "#         axes.append(ax)\n",
    "# for nar, ax in zip(selected_nar + ['other'], axes):\n",
    "#     ax.set_title(nar, position=(0.75, 0.85))\n",
    "#     ax.plot(get_gt_series(nar), label='tweet')\n",
    "#     ax.plot(get_west_series(nar), label='west')\n",
    "#     ax.plot(get_series(nar, string_match_series), label='string_match')\n",
    "#     ax.plot(get_series(nar, leidos_bert_series), label='leidos_bert')\n",
    "#     ax.legend()\n",
    "    \n",
    "#     ax.set_xticks(np.arange(len(all_dates))[::20])\n",
    "#     ax.set_xticklabels([i[-5:] for i in all_dates[::20]])\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib inline\n",
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "\n",
    "# def get_series(nar, s, norm='max'):\n",
    "#     tmp = [s[nar][i] for i in all_dates]\n",
    "#     if norm == 'max':\n",
    "#         x = max(*tmp)\n",
    "#     elif norm == 'sum':\n",
    "#         x = sum(tmp)\n",
    "#     else:\n",
    "#         x = 1\n",
    "#     x = max(x, 1e-5)\n",
    "#     return [i / x for i in tmp]\n",
    "\n",
    "# fig, _axes = plt.subplots(4, 3, figsize=(15, 12))\n",
    "# axes = []\n",
    "# for i in _axes:\n",
    "#     for ax in i:\n",
    "#         axes.append(ax)\n",
    "# for nar, ax in zip(selected_nar + ['other'], axes):\n",
    "#     ax.set_title(nar, position=(0.75, 0.85))\n",
    "#     ax.plot(get_gt_series(nar), label='tweet')\n",
    "#     ax.plot(get_west_series(nar), label='west')\n",
    "# #     ax.plot(get_series(nar, string_match_series), label='string_match')\n",
    "# #     ax.plot(get_series(nar, leidos_bert_series), label='leidos_bert')\n",
    "#     ax.legend()\n",
    "    \n",
    "#     ax.set_xticks(np.arange(len(all_dates))[::20])\n",
    "#     ax.set_xticklabels([i[-5:] for i in all_dates[::20]])\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib inline\n",
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "\n",
    "# def get_series(nar, s, norm='max'):\n",
    "#     tmp = [s[nar][i] for i in all_dates]\n",
    "#     if norm == 'max':\n",
    "#         x = max(*tmp)\n",
    "#     elif norm == 'sum':\n",
    "#         x = sum(tmp)\n",
    "#     else:\n",
    "#         x = 1\n",
    "#     x = max(x, 1e-5)\n",
    "#     return [i / x for i in tmp]\n",
    "\n",
    "# fig, _axes = plt.subplots(4, 3, figsize=(15, 12))\n",
    "# axes = []\n",
    "# for i in _axes:\n",
    "#     for ax in i:\n",
    "#         axes.append(ax)\n",
    "# for nar, ax in zip(selected_nar + ['other'], axes):\n",
    "#     ax.set_title(nar, position=(0.75, 0.85))\n",
    "#     ax.plot(get_gt_series(nar), label='tweet')\n",
    "# #     ax.plot(get_west_series(nar), label='west')\n",
    "#     ax.plot(get_series(nar, string_match_series), label='string_match')\n",
    "# #     ax.plot(get_series(nar, leidos_bert_series), label='leidos_bert')\n",
    "#     ax.legend()\n",
    "    \n",
    "#     ax.set_xticks(np.arange(len(all_dates))[::20])\n",
    "#     ax.set_xticklabels([i[-5:] for i in all_dates[::20]])\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib inline\n",
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "\n",
    "# def get_series(nar, s, norm='max'):\n",
    "#     tmp = [s[nar][i] for i in all_dates]\n",
    "#     if norm == 'max':\n",
    "#         x = max(*tmp)\n",
    "#     elif norm == 'sum':\n",
    "#         x = sum(tmp)\n",
    "#     else:\n",
    "#         x = 1\n",
    "#     x = max(x, 1e-5)\n",
    "#     return [i / x for i in tmp]\n",
    "\n",
    "# fig, _axes = plt.subplots(4, 3, figsize=(15, 12))\n",
    "# axes = []\n",
    "# for i in _axes:\n",
    "#     for ax in i:\n",
    "#         axes.append(ax)\n",
    "# for nar, ax in zip(selected_nar + ['other'], axes):\n",
    "#     ax.set_title(nar, position=(0.75, 0.85))\n",
    "#     ax.plot(get_gt_series(nar), label='tweet')\n",
    "# #     ax.plot(get_west_series(nar), label='west')\n",
    "# #     ax.plot(get_series(nar, string_match_series), label='string_match')\n",
    "#     ax.plot(get_series(nar, leidos_bert_series), label='leidos_bert')\n",
    "#     ax.legend()\n",
    "    \n",
    "#     ax.set_xticks(np.arange(len(all_dates))[::20])\n",
    "#     ax.set_xticklabels([i[-5:] for i in all_dates[::20]])\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the correlation matrix between gdelt event code and news frame\n",
    "corr_mat = dict()\n",
    "for target_method in ['leidos_bert', 'string_match', 'westclass']: # , 'lotclass', 'tuned_bert'\n",
    "    selected_dates = [i.strftime(\"%Y-%m-%d\") for i in pd.date_range(start=\"2020-03-30\",end=cor_end_date).to_pydatetime().tolist()]\n",
    "    selected_stamp = dict()\n",
    "    date2stamp = dict()\n",
    "    for d in selected_dates:\n",
    "        stamp = str(int(calendar.timegm(datetime.datetime.strptime(d, \"%Y-%m-%d\").timetuple()))) + '000'\n",
    "        selected_stamp[stamp] = d\n",
    "        date2stamp[d] = stamp\n",
    "\n",
    "    gdelt = defaultdict(dict)\n",
    "\n",
    "    for ec, series in json.load(open('../gdelt_time_series.json')).items():\n",
    "        series = json.loads(series)\n",
    "        for i in selected_dates:\n",
    "            gdelt[ec][i]  = series[date2stamp[i]]\n",
    "\n",
    "    # west classification\n",
    "    import numpy as np\n",
    "    eventcode_doc = defaultdict(int)\n",
    "    eventcode_nar_score = defaultdict(lambda:defaultdict(float))\n",
    "    for fn in all_news_results:\n",
    "        with open(f'{fn}') as fin:\n",
    "            for line in fin:\n",
    "                js = json.loads(line)\n",
    "                if js['eventcode'] and js[f'{target_method}_score']: # js['relevance_prediction'] and \n",
    "                    for ec in js['eventcode']:\n",
    "                        eventcode_doc[ec] += 1\n",
    "                        for nar in narratives:\n",
    "                            score = js[f'{target_method}_score'][nar]\n",
    "                            eventcode_nar_score[ec][nar] += score\n",
    "\n",
    "    eventCodeMap = {\"010\": 0, \"011\": 1, \"012\": 2, \"013\": 3, \"014\": 4, \"015\": 5, \"016\": 6, \"017\": 7, \"018\": 8, \"019\": 9, \"020\": 10, \"021\": 11, \"0211\": 12, \"0212\": 13, \"0213\": 14, \"0214\": 15, \"022\": 16, \"023\": 17, \"0231\": 18, \"0232\": 19, \"0233\": 20, \"0234\": 21, \"024\": 22, \"0241\": 23, \"0242\": 24, \"0243\": 25, \"0244\": 26, \"025\": 27, \"0253\": 28, \"0254\": 29, \"0256\": 30, \"026\": 31, \"027\": 32, \"028\": 33, \"030\": 34, \"031\": 35, \"0311\": 36, \"0312\": 37, \"0314\": 38, \"032\": 39, \"033\": 40, \"0331\": 41, \"0332\": 42, \"0333\": 43, \"0334\": 44, \"034\": 45, \"0341\": 46, \"0344\": 47, \"035\": 48, \"0351\": 49, \"0353\": 50, \"0356\": 51, \"036\": 52, \"037\": 53, \"038\": 54, \"039\": 55, \"040\": 56, \"041\": 57, \"042\": 58, \"043\": 59, \"044\": 60, \"045\": 61, \"046\": 62, \"050\": 63, \"051\": 64, \"052\": 65, \"053\": 66, \"054\": 67, \"055\": 68, \"056\": 69, \"057\": 70, \"060\": 71, \"061\": 72, \"062\": 73, \"063\": 74, \"064\": 75, \"070\": 76, \"071\": 77, \"072\": 78, \"073\": 79, \"074\": 80, \"075\": 81, \"080\": 82, \"081\": 83, \"0811\": 84, \"0813\": 85, \"0814\": 86, \"082\": 87, \"083\": 88, \"0831\": 89, \"0833\": 90, \"0834\": 91, \"084\": 92, \"0841\": 93, \"0842\": 94, \"085\": 95, \"086\": 96, \"0861\": 97, \"0862\": 98, \"0863\": 99, \"087\": 100, \"0871\": 101, \"0872\": 102, \"0873\": 103, \"0874\": 104, \"090\": 105, \"091\": 106, \"092\": 107, \"093\": 108, \"094\": 109, \"100\": 110, \"101\": 111, \"1013\": 112, \"1014\": 113, \"102\": 114, \"1031\": 115, \"1041\": 116, \"1043\": 117, \"1044\": 118, \"105\": 119, \"1051\": 120, \"1053\": 121, \"1054\": 122, \"1056\": 123, \"106\": 124, \"110\": 125, \"111\": 126, \"112\": 127, \"1121\": 128, \"1122\": 129, \"1123\": 130, \"1124\": 131, \"1125\": 132, \"113\": 133, \"114\": 134, \"115\": 135, \"116\": 136, \"120\": 137, \"121\": 138, \"122\": 139, \"123\": 140, \"1231\": 141, \"1232\": 142, \"1233\": 143, \"124\": 144, \"1241\": 145, \"1243\": 146, \"1244\": 147, \"1246\": 148, \"125\": 149, \"126\": 150, \"127\": 151, \"128\": 152, \"129\": 153, \"130\": 154, \"131\": 155, \"1312\": 156, \"1313\": 157, \"132\": 158, \"1322\": 159, \"133\": 160, \"134\": 161, \"136\": 162, \"137\": 163, \"138\": 164, \"1383\": 165, \"1384\": 166, \"139\": 167, \"140\": 168, \"141\": 169, \"1411\": 170, \"1412\": 171, \"142\": 172, \"143\": 173, \"144\": 174, \"145\": 175, \"150\": 176, \"151\": 177, \"152\": 178, \"153\": 179, \"154\": 180, \"160\": 181, \"161\": 182, \"162\": 183, \"1621\": 184, \"1623\": 185, \"163\": 186, \"164\": 187, \"166\": 188, \"170\": 189, \"171\": 190, \"1711\": 191, \"1712\": 192, \"172\": 193, \"1721\": 194, \"1722\": 195, \"1723\": 196, \"1724\": 197, \"173\": 198, \"174\": 199, \"175\": 200, \"180\": 201, \"181\": 202, \"182\": 203, \"1821\": 204, \"1822\": 205, \"1823\": 206, \"183\": 207, \"1831\": 208, \"1832\": 209, \"184\": 210, \"185\": 211, \"186\": 212, \"190\": 213, \"191\": 214, \"192\": 215, \"193\": 216, \"194\": 217, \"195\": 218, \"196\": 219, \"202\": 220, \"203\": 221}\n",
    "    # narrativeMap = {\"benefits/development/energy\": 0, \"benefits/development/roads\": 1, \"benefits/jobs\": 2, \"controversies/china/border\": 3, \"controversies/china/uighur\": 4, \"controversies/pakistan/bajwa\": 5, \"controversies/pakistan/baloch\": 6, \"controversies/pakistan/students\": 7, \"leadership/bajwa\": 8, \"leadership/sharif\": 9, \"opposition/propaganda\": 10}\n",
    "    # twitterGdeltMat_norm = [[0.0 for j in range(len(narrativeMap))] for i in range(len(eventCodeMap))]\n",
    "    # twitterGdeltMat_raw = [[0.0 for j in range(len(narrativeMap))] for i in range(len(eventCodeMap))]\n",
    "    twitterGdeltMat_norm = {i:{j:0.0 for j in eventCodeMap} for i in selected_nar}\n",
    "    twitterGdeltMat_raw = {i:{j:0.0 for j in eventCodeMap} for i in selected_nar}\n",
    "    for n2 in eventCodeMap:\n",
    "        for n1 in selected_nar:\n",
    "            twitterGdeltMat_norm[n1][n2] = eventcode_nar_score[n2][n1] / eventcode_doc[n2] if eventcode_doc[n2] > 0 else 0.0\n",
    "            twitterGdeltMat_raw[n1][n2] = eventcode_nar_score[n2][n1]\n",
    "    #         twitterGdeltMat_norm[eventCodeMap[n2]][narrativeMap[n1]] = eventcode_nar_score[n2][n1] / eventcode_doc[n2] if eventcode_doc[n2] > 0 else 0.0\n",
    "    #         twitterGdeltMat_raw[eventCodeMap[n2]][narrativeMap[n1]] = eventcode_nar_score[n2][n1]\n",
    "\n",
    "    # json.dump({'eventCodeMap':eventCodeMap,'narrativeMap':narrativeMap,'twitterGdeltMat':twitterGdeltMat_norm,'youtubeGdeltMat':twitterGdeltMat_norm}, open(f'/shared/data2/qiuwenda/CP5/output_to_0531/corrmat_west_{k}_norm.json', 'w'))\n",
    "    json.dump(twitterGdeltMat_norm, open(f'news_gdelt_{target_method}_corr_to_{cor_end_date2}.json', 'w'))\n",
    "    corr_mat[target_method] = twitterGdeltMat_norm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Hybrid correlation matrix: weighted sum\n",
    "# twitterGdeltMat_norm = {i:{j:0.0 for j in eventCodeMap} for i in selected_nar}\n",
    "# for nar in optimal_weighting:\n",
    "#     for method in optimal_weighting[nar]:\n",
    "#         for ec in corr_mat[method][nar]:\n",
    "#             twitterGdeltMat_norm[nar][ec] += optimal_weighting[nar][method] * corr_mat[method][nar][ec]\n",
    "# for nar in twitterGdeltMat_norm:\n",
    "#     for ec in twitterGdeltMat_norm[nar]:\n",
    "#         twitterGdeltMat_norm[nar][ec] /= sum(optimal_weighting[nar].values())\n",
    "# json.dump(twitterGdeltMat_norm, open(f'news_gdelt_weighted_5_hybrid_corr_to_{cor_end_date2}.json', 'w'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Hybrid correlation matrix: per-frame-per-method\n",
    "# twitterGdeltMat_norm = {i:{j:0.0 for j in eventCodeMap} for i in selected_nar}\n",
    "# for nar in optimal_weighting:\n",
    "#     method = nar2optimal_choice[nar]\n",
    "#     for ec in corr_mat[method][nar]:\n",
    "#         twitterGdeltMat_norm[nar][ec] += optimal_weighting[nar][method] * corr_mat[method][nar][ec]\n",
    "# json.dump(twitterGdeltMat_norm, open(f'news_gdelt_pfpm_5_hybrid_corr_to_{cor_end_date2}.json', 'w'))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-15T19:59:05.090511Z",
     "start_time": "2021-01-15T19:59:01.563647Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    }
   ],
   "source": [
    "import pytorch_lightning as pl\n",
    "import os\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, IterableDataset\n",
    "from transformers import BertTokenizer, BertModel, BertConfig\n",
    "from transformers import AlbertTokenizer, AlbertModel, AlbertConfig\n",
    "from transformers import AdamW\n",
    "from transformers import get_constant_schedule_with_warmup\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "import transformers\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import argparse\n",
    "from pytorch_lightning import Trainer, seed_everything\n",
    "from pytorch_lightning import loggers as pl_logger\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "from pytorch_lightning.metrics import F1, Precision, Recall\n",
    "\n",
    "seed_everything(42)\n",
    "\n",
    "\n",
    "def encoding_text(d):\n",
    "    inputs = tokenizer.encode(d, return_tensors=\"pt\", truncation=True, padding='max_length', max_length=256)\n",
    "    return inputs.squeeze()\n",
    "\n",
    "\n",
    "class BertClassifier(pl.LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.cls = transformers.BertForSequenceClassification.from_pretrained('bert-base-multilingual-uncased')\n",
    "        self.softmax = torch.nn.Softmax(dim=-1)\n",
    "        self.crossentropy = torch.nn.CrossEntropyLoss()\n",
    "        self.f1 = F1()\n",
    "        self.p = Precision()\n",
    "        self.r = Recall()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.softmax(self.cls(x).logits)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, label = batch\n",
    "        pred = self.forward(x)\n",
    "        loss = self.crossentropy(pred, label)\n",
    "        self.log(\"loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, label = batch\n",
    "        logits = self.forward(x)\n",
    "        return label, logits[:,1]\n",
    "    \n",
    "    def evaluate_outs(self, outs):\n",
    "        labels = torch.cat([label for label, pred in outs])\n",
    "        preds = torch.cat([pred for label, pred in outs])\n",
    "        f1 = self.f1(preds, labels)\n",
    "        p = self.p(preds, labels)\n",
    "        r = self.r(preds, labels)\n",
    "        return f1, p, r\n",
    "    \n",
    "    def validation_epoch_end(self, outs):\n",
    "        f1, p, r = self.evaluate_outs(outs)\n",
    "        print('f1', f1)\n",
    "        print('p', p)\n",
    "        print('r', r)\n",
    "        self.log(\"val_f1\", f1)\n",
    "        self.log(\"val_p\", p)\n",
    "        self.log(\"val_r\", r)\n",
    "        return f1\n",
    "    \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        return self.validation_step(batch, batch_idx)\n",
    "    \n",
    "    def test_epoch_end(self, outs):\n",
    "        f1, p, r = self.evaluate_outs(outs)\n",
    "        self.log(\"test_f1\", f1)\n",
    "        self.log(\"test_p\", p)\n",
    "        self.log(\"test_r\", r)\n",
    "        return f1\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = AdamW(self.parameters(), lr=lr)\n",
    "        scheduler = get_linear_schedule_with_warmup(\n",
    "            optimizer, num_warmup_steps=warmup_steps,\n",
    "            num_training_steps=num_training_steps,\n",
    "        )\n",
    "        return [optimizer], [scheduler]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "434357\n",
      "43435\n"
     ]
    }
   ],
   "source": [
    "import pytorch_lightning as pl\n",
    "import os\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, IterableDataset\n",
    "lr = 1e-4\n",
    "warmup_steps = 50\n",
    "batch_size = 80\n",
    "maximum_training = 1000000\n",
    "epochs = 8\n",
    "dataset = binary_dataset('tweet_text_for_relevance.json', maximum_training)\n",
    "\n",
    "\n",
    "print(len(dataset))\n",
    "val_size = int(0.1 * len(dataset))\n",
    "test_size = int(0.1 * len(dataset))\n",
    "train_size = len(dataset) - val_size - test_size\n",
    "print(val_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-15T19:59:05.327323Z",
     "start_time": "2021-01-15T19:59:05.092547Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19b2c841c56c478bbd9b975d3d24c3f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/872k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-uncased')\n",
    "\n",
    "import json\n",
    "class binary_dataset(Dataset):\n",
    "    def __init__(self, fn, maximum_training=-1):\n",
    "        self.X = []\n",
    "        self.Y = []\n",
    "        with open(fn) as fin:\n",
    "            for line in fin:\n",
    "                js = json.loads(line)\n",
    "                self.Y.append(js['label'])\n",
    "                self.X.append(js['text'])\n",
    "                if maximum_training != -1 and len(self.X) > maximum_training:\n",
    "                    break\n",
    "    def __getitem__(self, idx):\n",
    "        return encoding_text(self.X[idx]), int(self.Y[idx])\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'binary_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-defa21328969>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbinary_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'tweet_text_for_relevance.json'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaximum_training\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mval_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.1\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mtest_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.1\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'binary_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "\n",
    "lr = 1e-4\n",
    "warmup_steps = 50\n",
    "batch_size = 80\n",
    "maximum_training = 1000000\n",
    "epochs = 8\n",
    "\n",
    "dataset = binary_dataset('tweet_text_for_relevance.json', maximum_training)\n",
    "val_size = int(0.1 * len(dataset))\n",
    "test_size = int(0.1 * len(dataset))\n",
    "train_size = len(dataset) - val_size - test_size\n",
    "train_set, val_set, test_set = torch.utils.data.random_split(dataset, [train_size, val_size, test_size])\n",
    "num_training_steps = len(train_set) // batch_size * epochs\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size, num_workers=128, shuffle=True)\n",
    "val_loader = DataLoader(val_set, batch_size=batch_size, num_workers=128)\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor='val_f1',\n",
    "    dirpath='./',\n",
    "    filename='relevance_model_tweet_best_f1',\n",
    "    save_top_k=1,\n",
    "    mode='max',\n",
    ")\n",
    "trainer = pl.Trainer(max_epochs=epochs, gpus=[0], precision=16, default_root_dir='checkpoints', callbacks=[checkpoint_callback])\n",
    "\n",
    "model = BertClassifier()\n",
    "# trainer.fit(model, train_loader, val_loader)\n",
    "\n",
    "model = BertClassifier.load_from_checkpoint('./relevance_model_tweet_best_f1.ckpt')\n",
    "test_loader = DataLoader(test_set, batch_size=batch_size, num_workers=128)\n",
    "trainer.test(model, test_dataloaders=test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-15T19:59:32.289821Z",
     "start_time": "2021-01-15T19:59:21.585289Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/qiuwenda/anaconda3/envs/pytorch/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: Checkpoint directory ./ exists and is not empty.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Using native 16bit precision.\n",
      "Some weights of the model checkpoint at bert-base-multilingual-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\n",
      "  | Name         | Type                          | Params\n",
      "---------------------------------------------------------------\n",
      "0 | cls          | BertForSequenceClassification | 167 M \n",
      "1 | softmax      | Softmax                       | 0     \n",
      "2 | crossentropy | CrossEntropyLoss              | 0     \n",
      "3 | f1           | F1                            | 0     \n",
      "4 | p            | Precision                     | 0     \n",
      "5 | r            | Recall                        | 0     \n",
      "---------------------------------------------------------------\n",
      "167 M     Trainable params\n",
      "0         Non-trainable params\n",
      "167 M     Total params\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validation sanity check'), FloatProgress(value=1.0, bar_style='info', layout=Layout…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 tensor(0., device='cuda:0')\n",
      "p tensor(0., device='cuda:0')\n",
      "r tensor(0., device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/qiuwenda/anaconda3/envs/pytorch/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The validation_epoch_end should not return anything as of 9.1. To log, use self.log(...) or self.write(...) directly in the LightningModule\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cb62d38941f45ef9ebba57ef068bae4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Training'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 tensor(0.0718, device='cuda:0')\n",
      "p tensor(0.7188, device='cuda:0')\n",
      "r tensor(0.0378, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/qiuwenda/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:216: UserWarning: Please also save or load the state of the optimizer when saving or loading the scheduler.\n",
      "  warnings.warn(SAVE_STATE_WARNING, UserWarning)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 tensor(0.4244, device='cuda:0')\n",
      "p tensor(0.6290, device='cuda:0')\n",
      "r tensor(0.3202, device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 tensor(0.6169, device='cuda:0')\n",
      "p tensor(0.6375, device='cuda:0')\n",
      "r tensor(0.5977, device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 tensor(0.6423, device='cuda:0')\n",
      "p tensor(0.7031, device='cuda:0')\n",
      "r tensor(0.5911, device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 tensor(0.6442, device='cuda:0')\n",
      "p tensor(0.7224, device='cuda:0')\n",
      "r tensor(0.5813, device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 tensor(0.6608, device='cuda:0')\n",
      "p tensor(0.7173, device='cuda:0')\n",
      "r tensor(0.6125, device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 tensor(0.6540, device='cuda:0')\n",
      "p tensor(0.7293, device='cuda:0')\n",
      "r tensor(0.5928, device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 tensor(0.6667, device='cuda:0')\n",
      "p tensor(0.7114, device='cuda:0')\n",
      "r tensor(0.6273, device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 tensor(0.6706, device='cuda:0')\n",
      "p tensor(0.6849, device='cuda:0')\n",
      "r tensor(0.6568, device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 tensor(0.6655, device='cuda:0')\n",
      "p tensor(0.7173, device='cuda:0')\n",
      "r tensor(0.6207, device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 tensor(0.6697, device='cuda:0')\n",
      "p tensor(0.7536, device='cuda:0')\n",
      "r tensor(0.6026, device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 tensor(0.6667, device='cuda:0')\n",
      "p tensor(0.6991, device='cuda:0')\n",
      "r tensor(0.6371, device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 tensor(0.6661, device='cuda:0')\n",
      "p tensor(0.7347, device='cuda:0')\n",
      "r tensor(0.6092, device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 tensor(0.6725, device='cuda:0')\n",
      "p tensor(0.7140, device='cuda:0')\n",
      "r tensor(0.6355, device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 tensor(0.6516, device='cuda:0')\n",
      "p tensor(0.7667, device='cuda:0')\n",
      "r tensor(0.5665, device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 tensor(0.6719, device='cuda:0')\n",
      "p tensor(0.7106, device='cuda:0')\n",
      "r tensor(0.6371, device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 tensor(0.6643, device='cuda:0')\n",
      "p tensor(0.7399, device='cuda:0')\n",
      "r tensor(0.6026, device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 tensor(0.6563, device='cuda:0')\n",
      "p tensor(0.7453, device='cuda:0')\n",
      "r tensor(0.5862, device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 tensor(0.6497, device='cuda:0')\n",
      "p tensor(0.7644, device='cuda:0')\n",
      "r tensor(0.5649, device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 tensor(0.6860, device='cuda:0')\n",
      "p tensor(0.7120, device='cuda:0')\n",
      "r tensor(0.6617, device='cuda:0')\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-multilingual-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c36de6c80e724581807a3cff281cd2c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Testing'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), max=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'test_f1': tensor(0.6537, device='cuda:0'),\n",
      " 'test_p': tensor(0.6862, device='cuda:0'),\n",
      " 'test_r': tensor(0.6242, device='cuda:0')}\n",
      "--------------------------------------------------------------------------------\n",
      "split test [{'test_f1': 0.6537162065505981, 'test_p': 0.686170220375061, 'test_r': 0.624193549156189}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/qiuwenda/anaconda3/envs/pytorch/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: The testing_epoch_end should not return anything as of 9.1. To log, use self.log(...) or self.write(...) directly in the LightningModule\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ede7e9a395949ddbcd05e4a544bc4d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Testing'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), max=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'test_f1': tensor(0.7067, device='cuda:0'),\n",
      " 'test_p': tensor(0.9636, device='cuda:0'),\n",
      " 'test_r': tensor(0.5579, device='cuda:0')}\n",
      "--------------------------------------------------------------------------------\n",
      "manual test [{'test_f1': 0.7066667079925537, 'test_p': 0.9636363387107849, 'test_r': 0.557894766330719}]\n"
     ]
    }
   ],
   "source": [
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "\n",
    "lr = 5e-5\n",
    "warmup_steps = 50\n",
    "batch_size = 64\n",
    "maximum_training = 5000000\n",
    "epochs = 20\n",
    "\n",
    "dataset = binary_dataset('tweet_news_text_for_relevance.json', maximum_training)\n",
    "val_size = int(0.1 * len(dataset))\n",
    "test_size = int(0.1 * len(dataset))\n",
    "train_size = len(dataset) - val_size - test_size\n",
    "train_set, val_set, test_set = torch.utils.data.random_split(dataset, [train_size, val_size, test_size])\n",
    "num_training_steps = len(train_set) // batch_size * epochs\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size, num_workers=128, shuffle=True, pin_memory=True)\n",
    "val_loader = DataLoader(val_set, batch_size=batch_size, num_workers=128, pin_memory=True)\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor='val_f1',\n",
    "    dirpath='./',\n",
    "    filename='relevance_model_best_f1',\n",
    "    save_top_k=1,\n",
    "    mode='max',\n",
    ")\n",
    "trainer = pl.Trainer(max_epochs=epochs, gpus=[0], precision=16, default_root_dir='checkpoints', callbacks=[checkpoint_callback])\n",
    "\n",
    "model = BertClassifier.load_from_checkpoint('./relevance_model_tweet_best_f1.ckpt')\n",
    "trainer.fit(model, train_loader, val_loader)\n",
    "\n",
    "model = BertClassifier.load_from_checkpoint('./relevance_model_best_f1.ckpt')\n",
    "test_loader = DataLoader(test_set, batch_size=256, num_workers=128, pin_memory=True)\n",
    "print('split test', trainer.test(model, test_dataloaders=test_loader))\n",
    "\n",
    "test_loader2 = DataLoader(binary_dataset('manual_news_text_for_relevance.json'), batch_size=256, num_workers=128, pin_memory=True)\n",
    "print('manual test', trainer.test(model, test_dataloaders=test_loader2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "split test [{'test_f1': 0.6537162065505981, 'test_p': 0.686170220375061, 'test_r': 0.624193549156189}]\n",
    "manual test [{'test_f1': 0.7066667079925537, 'test_p': 0.9636363387107849, 'test_r': 0.557894766330719}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-multilingual-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "forward() got an unexpected keyword argument 'return_dict'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-aa32c6dd79e6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_loader2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mtmp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cuda'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mpred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: forward() got an unexpected keyword argument 'return_dict'"
     ]
    }
   ],
   "source": [
    "# Find threshold\n",
    "model = BertClassifier.load_from_checkpoint('./relevance_model_best_f1.ckpt')\n",
    "test_loader2 = DataLoader(binary_dataset('future_manual_news_text_for_relevance.json'), batch_size=256, num_workers=128, pin_memory=True)\n",
    "model.eval()\n",
    "model.to('cuda')\n",
    "Y = []\n",
    "pred = []\n",
    "with torch.no_grad():\n",
    "    for x, y in test_loader2:\n",
    "        tmp = model(x.to('cuda'), return_dict=True)[:,1].detach().cpu().numpy()\n",
    "        Y.extend(y.numpy())\n",
    "        pred.extend(tmp)\n",
    "print(len(Y), len(pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.1355447e-06\n",
      "0.8148148148148148 0.9428571428571428 0.717391304347826\n"
     ]
    }
   ],
   "source": [
    "best_threshold = 4.1355447e-06\n",
    "pred = np.array(pred)\n",
    "# best_f1 = -1\n",
    "# print(sorted(pred))\n",
    "# for threshold in pred:\n",
    "#     f1 = f1_score(Y, pred >= threshold)\n",
    "#     if best_f1 < f1:\n",
    "#         best_f1 = f1\n",
    "#         best_threshold = threshold\n",
    "\n",
    "print(best_threshold)\n",
    "threshold = best_threshold\n",
    "f1 = f1_score(Y, pred >= threshold)\n",
    "p = precision_score(Y, pred >= threshold)\n",
    "r = recall_score(Y, pred >= threshold)\n",
    "print(f1, p, r)\n",
    "\n",
    "# loader1 : 0.6362968405584128 0.6983870967741935 0.5843454790823212\n",
    "# loader2 : 0.811764705882353 0.7263157894736842 0.92\n",
    "\n",
    "# 4.1355447e-06\n",
    "# 0.8148148148148148 0.9428571428571428 0.717391304347826"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-multilingual-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "100%|██████████| 673/673 [19:51<00:00,  1.77s/it]   \n"
     ]
    }
   ],
   "source": [
    "# generate relevance score for all news\n",
    "model = BertClassifier.load_from_checkpoint('./relevance_model_best_f1.ckpt')\n",
    "class inference_dataset(Dataset):\n",
    "    def __init__(self):\n",
    "        self.X = []\n",
    "        with open('../news_text_raw.json') as fin:\n",
    "            for line in fin:\n",
    "                i = json.loads(line)\n",
    "                text = (i['title'] if i['title'] else ' ') + ' ' + (i['article'] if i['article'] else ' ')\n",
    "                self.X.append(text)\n",
    "    def __getitem__(self, idx):\n",
    "        return encoding_text(self.X[idx])\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "inference_set = inference_dataset()\n",
    "inference_loader = DataLoader(inference_set, batch_size=256, num_workers=128, shuffle=False, drop_last=False)\n",
    "relevance_scores = []\n",
    "relevance_predictions = []\n",
    "with torch.no_grad():\n",
    "    model.eval().to('cuda')\n",
    "    for batch in tqdm(inference_loader):\n",
    "        tmp = model(batch.to('cuda'))[:,1].detach().cpu().numpy()\n",
    "        relevance_scores.extend(tmp)\n",
    "        relevance_predictions.extend(tmp >= best_threshold)\n",
    "all_data = []\n",
    "with open('../news_text_raw.json') as fin:\n",
    "    for line in fin:\n",
    "        i = json.loads(line)\n",
    "        all_data.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36417\n"
     ]
    }
   ],
   "source": [
    "url2gt = dict()\n",
    "with open('tweet_news_text_for_relevance.json') as fin:\n",
    "    for line in fin:\n",
    "        js = json.loads(line)\n",
    "        url2gt[js['url']] = js['label']\n",
    "with open('manual_news_text_for_relevance.json') as fin:\n",
    "    for line in fin:\n",
    "        js = json.loads(line)\n",
    "        url2gt[js['url']] = js['label']\n",
    "assert len(all_data) == len(relevance_scores)\n",
    "with open('url2relevance.json', 'w') as fout:\n",
    "    for js, score, pred in zip(all_data, relevance_scores, relevance_predictions):\n",
    "        if js['url'] in url2gt:\n",
    "            js['relevance_prediction'] = url2gt[js['url']]\n",
    "            js['relevance_score'] = 1.0 if js['relevance_prediction'] else 0.0\n",
    "        else:\n",
    "            js['relevance_score'] = float(score)\n",
    "            js['relevance_prediction'] = bool(pred)\n",
    "        fout.write(json.dumps({'url': js['url'], 'relevance_score': js['relevance_score'], 'relevance_prediction': js['relevance_prediction']}) + '\\n')\n",
    "        \n",
    "cnt = 0\n",
    "for js in all_data:\n",
    "    if js['relevance_prediction'] and js['lang'] == 'en':\n",
    "        cnt += 1\n",
    "print(cnt)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
